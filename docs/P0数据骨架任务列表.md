## P0 数据骨架任务列表

### 概述
目标：在 3~4 周内完成多源采集→流式缓冲→数据清洗→数据落地的完整闭环，为上层策略提供稳定数据输入。

### 任务清单
| 编号 | 模块 | 任务描述 | 负责人 (待定) | 预计工期 | 依赖 |
| --- | --- | --- | --- | --- | --- |
| P0-01 | 项目治理 | 完成 Kickoff 会议、会议纪要、项目看板搭建 |  | 1d | - |
| P0-02 | 架构决策 | 编写数据管道、消息系统、Schema 的 ADR 文档 |  | 3d | P0-01 |
| P0-03 | 数据源适配 | 抽象 `DataSourceAdapter` 接口，整理配置与密钥管理方案 |  | 3d | P0-02 |
| P0-04 | 腾讯数据源 | 实现腾讯行情抓取脚本，支持分时/逐笔，带节流与重试 |  | 4d | P0-03 |
| P0-05 | 东方财富数据源 | 同上，支持分时数据 |  | 4d | P0-03 |
| P0-06 | Tushare 备援 | 实现基础版本，仅在主源失败时启用 |  | 3d | P0-03 |
| P0-07 | collector 服务 | 编写 `collector-gateway` 主程序，整合各数据源并推送 Redis Stream |  | 5d | P0-04/05/06 |
| P0-08 | 指标监控 | 为 `collector-gateway` 加入 Prometheus 指标与健康检查 |  | 2d | P0-07 |
| P0-09 | stream 架设 | 初始化 Redis Stream / Kafka topic、消费者组及权限 |  | 2d | P0-02 |
| P0-10 | 清洗模块 | 实现 `data-cleaner` 消费者，完成时间对齐、缺失/异常处理 |  | 5d | P0-07/09 |
| P0-11 | 数据质量 | 定义质量指标（延迟、缺失率、异常数），写入监控 |  | 3d | P0-10 |
| P0-12 | 实时缓存 | 将清洗数据写入 Redis Hash/Timeseries，提供查询接口 |  | 3d | P0-10 |
| P0-13 | 数据落地 | 实现 `data-lake-writer` 批量写入 Parquet/ClickHouse |  | 5d | P0-10 |
| P0-14 | 落地调度 | 配置 Prefect/Airflow 定时任务与失败重试策略 |  | 3d | P0-13 |
| P0-15 | 验证测试 | 编写端到端集成测试、数据完整性校验脚本 |  | 4d | P0-07/10/13 |
| P0-16 | 交付验收 | 连续运行 24 小时无重大异常，输出验证报告 |  | 2d | P0-15 |

> 负责人、实际工期与依赖需在 Kickoff 后确认并持续更新。

### 里程碑验收标准
- Stream 数据断流率 < 0.1%，延迟 < 2s。
- 数据清洗后缺失率 < 0.5%，异常纠正率 > 95%。
- 数据湖每日归档成功率 ≥ 99%。
- 关键指标在 Grafana 可视化并设定告警阈值。

### 风险提示
- 数据源 IP/账号限制导致抓取失败。
- Redis Stream 性能瓶颈需提前压测。
- 清洗规则不完善导致特征异常。
- 人力资源冲突或交付顺序延误。

### 沟通机制
- 每日 Standup 汇报进度与阻塞。
- 每周阶段复盘，更新任务看板与风险表。
- 工作完成后提交验证报告进入代码评审。
