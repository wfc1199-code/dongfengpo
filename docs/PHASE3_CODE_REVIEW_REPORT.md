# Phase 3 ä»£ç å®¡æŸ¥æŠ¥å‘Šï¼šå®ç›˜å¼•æ“ä¸ AI é›†æˆ

**å®¡æŸ¥æ—¥æœŸ**: 2025-01-XX  
**å®¡æŸ¥èŒƒå›´**: å®ç›˜å¼•æ“ä¸ AI é›†æˆæ¨¡å—ï¼ˆ3ä¸ªæ ¸å¿ƒæ–‡ä»¶ï¼‰  
**å®¡æŸ¥ç»´åº¦**: å¼‚æ­¥å®‰å…¨ã€èµ„æºç®¡ç†ã€å®‰å…¨æ€§ã€é”™è¯¯å¤„ç†ã€å¯æµ‹è¯•æ€§

---

## ğŸ“‹ å®¡æŸ¥æ¦‚è§ˆ

| æ–‡ä»¶ | Critical | Warning | Info | æ€»ä½“è¯„åˆ† |
|------|----------|---------|------|----------|
| `engines/realtime.py` | 3 | 5 | 3 | âš ï¸ éœ€æ”¹è¿› |
| `ai/deepseek_client.py` | 2 | 4 | 2 | âš ï¸ éœ€æ”¹è¿› |
| `ai/audit.py` | 1 | 3 | 2 | âœ… è‰¯å¥½ |

**æ€»è®¡**: 6 Critical, 12 Warning, 7 Info

---

## ğŸ”´ æ–‡ä»¶ 1: `engines/realtime.py`

### Critical é—®é¢˜

#### 1. å¼‚æ­¥å¾ªç¯å–æ¶ˆå¤„ç†ä¸å®Œæ•´ (Line 137-174)
**ä¸¥é‡ç¨‹åº¦**: ğŸ”´ Critical  
**é—®é¢˜**: `start()` æ–¹æ³•ä¸­çš„å¾ªç¯åœ¨å–æ¶ˆæ—¶å¯èƒ½æ— æ³•æ­£ç¡®æ¸…ç†èµ„æº

**å½“å‰ä»£ç **:
```python
async def start(self, symbols: List[str]):
    # ...
    while self._running:
        try:
            if self.is_trading_hours():
                await self._tick(symbols)
            else:
                logger.debug("Outside trading hours, waiting...")
            
            await asyncio.sleep(self.config.polling_interval_seconds)
            
        except asyncio.CancelledError:
            logger.info("Engine stop requested")
            break
        except Exception as e:
            logger.error(f"Error in engine loop: {e}")
            await asyncio.sleep(5)  # Wait before retry
```

**é—®é¢˜**:
- `stop()` åªæ˜¯è®¾ç½® `_running = False`ï¼Œå¦‚æœå¾ªç¯æ­£åœ¨ `asyncio.sleep()` ä¸­ï¼Œéœ€è¦ç­‰å¾…
- æ²¡æœ‰ä½¿ç”¨ `asyncio.Event` æˆ– `asyncio.Task` æ¥ä¼˜é›…å–æ¶ˆ
- å¦‚æœ `_tick()` ä¸­åˆ›å»ºäº†å­ä»»åŠ¡ï¼Œå–æ¶ˆæ—¶å¯èƒ½æ³„æ¼

**ä¿®å¤å»ºè®®**:
```python
async def start(self, symbols: List[str]):
    """Start the realtime engine."""
    if self._running:
        logger.warning("Engine already running")
        return
    
    if not self.strategy:
        raise RuntimeError("No strategy set. Call set_strategy() first.")
    
    self._running = True
    self._stop_event = asyncio.Event()  # Add stop event
    logger.info(f"Starting realtime engine for {len(symbols)} symbols")
    
    # Reset daily counters
    self.risk_manager.reset_daily()
    
    # Main loop
    try:
        while self._running and not self._stop_event.is_set():
            try:
                if self.is_trading_hours():
                    await self._tick(symbols)
                else:
                    logger.debug("Outside trading hours, waiting...")
                
                # Use wait_for to allow cancellation
                try:
                    await asyncio.wait_for(
                        self._stop_event.wait(),
                        timeout=self.config.polling_interval_seconds
                    )
                    # Event was set, stop requested
                    break
                except asyncio.TimeoutError:
                    # Timeout is expected, continue loop
                    pass
                
            except asyncio.CancelledError:
                logger.info("Engine stop requested (cancelled)")
                break
            except Exception as e:
                logger.error(f"Error in engine loop: {e}", exc_info=True)
                # Wait before retry, but check stop event
                try:
                    await asyncio.wait_for(self._stop_event.wait(), timeout=5)
                    break
                except asyncio.TimeoutError:
                    pass
    
    finally:
        # Cleanup
        self._running = False
        logger.info("Realtime engine stopped")

async def stop(self):
    """Stop the realtime engine gracefully."""
    if not self._running:
        return
    
    logger.info("Stopping realtime engine...")
    self._running = False
    
    # Signal stop event
    if hasattr(self, '_stop_event'):
        self._stop_event.set()
    
    # Wait for loop to finish (with timeout)
    # Note: In production, you might want to cancel the task instead
```

#### 2. äº¤æ˜“æ—¶æ®µæ£€æµ‹é€»è¾‘ä¸å®Œæ•´ (Line 129-135)
**ä¸¥é‡ç¨‹åº¦**: ğŸ”´ Critical  
**é—®é¢˜**: åªæ£€æŸ¥äº†åˆä¼‘å¼€å§‹ï¼Œæ²¡æœ‰æ£€æŸ¥åˆä¼‘ç»“æŸ

**å½“å‰ä»£ç **:
```python
def is_trading_hours(self) -> bool:
    """Check if current time is within trading hours."""
    now = datetime.now().time()
    # Skip lunch break (11:30 - 13:00)
    if time(11, 30) <= now < time(13, 0):
        return False
    return self.config.trading_start <= now <= self.config.trading_end
```

**é—®é¢˜**:
- å¦‚æœ `trading_start = 9:30`, `trading_end = 15:00`ï¼Œé‚£ä¹ˆ 13:00-15:00 åº”è¯¥è¿”å› True
- ä½†å½“å‰é€»è¾‘ï¼š`9:30 <= 13:00 <= 15:00` ä¼šè¿”å› Trueï¼Œè¿™æ˜¯å¯¹çš„
- ä½†æ›´æ¸…æ™°çš„åšæ³•æ˜¯åˆ†åˆ«æ£€æŸ¥ä¸Šåˆå’Œä¸‹åˆæ—¶æ®µ

**ä¿®å¤å»ºè®®**:
```python
def is_trading_hours(self) -> bool:
    """Check if current time is within trading hours."""
    now = datetime.now().time()
    
    # Morning session: 9:30 - 11:30
    morning_start = self.config.trading_start
    morning_end = time(11, 30)
    
    # Afternoon session: 13:00 - 15:00
    afternoon_start = time(13, 0)
    afternoon_end = self.config.trading_end
    
    # Check if in morning or afternoon session
    in_morning = morning_start <= now <= morning_end
    in_afternoon = afternoon_start <= now <= afternoon_end
    
    return in_morning or in_afternoon
```

#### 3. æ­¢æŸæ‰§è¡Œæ—¶æœºé—®é¢˜ (Line 197-201)
**ä¸¥é‡ç¨‹åº¦**: ğŸ”´ Critical  
**é—®é¢˜**: åœ¨æ›´æ–°ä»·æ ¼åç«‹å³æ‰§è¡Œæ­¢æŸï¼Œä½†åº”è¯¥å…ˆæ£€æŸ¥é€€å‡ºæ¡ä»¶ï¼Œå†æ›´æ–°ä»·æ ¼

**å½“å‰ä»£ç **:
```python
# Update risk manager with current prices
stop_loss_symbols = self.risk_manager.update_prices(self._latest_prices)

# Execute stop-loss orders
for symbol in stop_loss_symbols:
    await self._execute_stop_loss(symbol)
```

**é—®é¢˜**: 
- `update_prices()` ä¼šæ›´æ–°æŒä»“ä»·æ ¼ï¼Œç„¶åæ£€æŸ¥æ­¢æŸ
- ä½†å¦‚æœä»·æ ¼åœ¨ `_tick()` å¼€å§‹æ—¶å·²ç»è§¦å‘æ­¢æŸï¼Œåº”è¯¥ç«‹å³æ‰§è¡Œ
- å½“å‰é€»è¾‘å¯èƒ½å¯¼è‡´å»¶è¿Ÿæ‰§è¡Œ

**ä¿®å¤å»ºè®®**:
```python
async def _tick(self, symbols: List[str]):
    """Single tick of the engine loop."""
    # Fetch latest data
    data = await self._fetch_realtime_data(symbols)
    if data.empty:
        return
    
    self._latest_data = data
    
    # Update prices first
    for _, row in data.iterrows():
        symbol = row.get('symbol', row.get('code', 'UNKNOWN'))
        price = row.get('price', row.get('close', 0))
        self._latest_prices[symbol] = price
    
    # Check stop-loss BEFORE processing new signals
    # This ensures we exit losing positions before opening new ones
    stop_loss_symbols = self.risk_manager.update_prices(self._latest_prices)
    
    # Execute stop-loss orders immediately
    for symbol in stop_loss_symbols:
        await self._execute_stop_loss(symbol)
    
    # Then process new signals
    for symbol in symbols:
        symbol_data = data[data.get('symbol', data.get('code', '')) == symbol]
        if symbol_data.empty:
            continue
        
        await self._process_symbol(symbol, symbol_data)
```

### Warning é—®é¢˜

#### 4. ç¼ºå°‘ Context Manager æ”¯æŒ
**ä¸¥é‡ç¨‹åº¦**: âš ï¸ Warning  
**é—®é¢˜**: æ²¡æœ‰ `__aenter__`/`__aexit__`ï¼Œæ— æ³•ä½¿ç”¨ `async with` è¯­å¥

**ä¿®å¤å»ºè®®**:
```python
async def __aenter__(self):
    return self

async def __aexit__(self, exc_type, exc_val, exc_tb):
    await self.stop()
    return False
```

#### 5. æ•°æ®è·å–å¤±è´¥å¤„ç†ä¸å®Œå–„ (Line 211-260)
**ä¸¥é‡ç¨‹åº¦**: âš ï¸ Warning  
**é—®é¢˜**: AkShare æ•°æ®è·å–å¤±è´¥æ—¶åªè¿”å›ç©º DataFrameï¼Œæ²¡æœ‰é‡è¯•æœºåˆ¶

**ä¿®å¤å»ºè®®**: æ·»åŠ é‡è¯•é€»è¾‘å’Œæ›´è¯¦ç»†çš„é”™è¯¯å¤„ç†

#### 6. ç­–ç•¥æ•°æ®æ›´æ–°å¯èƒ½æœ‰é—®é¢˜ (Line 268-269)
**ä¸¥é‡ç¨‹åº¦**: âš ï¸ Warning  
**é—®é¢˜**: æ¯æ¬¡ tick éƒ½è°ƒç”¨ `strategy.set_data(data)`ï¼Œå¦‚æœæ•°æ®æ ¼å¼ä¸å®Œæ•´å¯èƒ½å¯¼è‡´ç­–ç•¥é‡ç½®

**ä¿®å¤å»ºè®®**: æ£€æŸ¥æ•°æ®å®Œæ•´æ€§ï¼Œæˆ–ä½¿ç”¨å¢é‡æ›´æ–°

#### 7. ç¼ºå°‘å¹¶å‘æ§åˆ¶
**ä¸¥é‡ç¨‹åº¦**: âš ï¸ Warning  
**é—®é¢˜**: å¤šä¸ª symbol çš„ `_process_symbol()` å¯èƒ½å¹¶å‘æ‰§è¡Œï¼Œæ²¡æœ‰æ§åˆ¶

**ä¿®å¤å»ºè®®**: ä½¿ç”¨ `asyncio.Semaphore` é™åˆ¶å¹¶å‘æ•°

#### 8. æ¨¡æ‹Ÿæ•°æ®å¯èƒ½ä¸çœŸå®
**ä¸¥é‡ç¨‹åº¦**: âš ï¸ Warning  
**é—®é¢˜**: æ¨¡æ‹Ÿæ¨¡å¼ä½¿ç”¨éšæœºæ¸¸èµ°ï¼Œå¯èƒ½ä¸å¤ŸçœŸå®

**ä¿®å¤å»ºè®®**: ä½¿ç”¨å†å²æ•°æ®å›æ”¾æˆ–æ›´çœŸå®çš„æ¨¡æ‹Ÿ

### Info é—®é¢˜

#### 9. ç¼ºå°‘æ€§èƒ½ç›‘æ§
**å»ºè®®**: æ·»åŠ  tick å»¶è¿Ÿã€ä¿¡å·ç”Ÿæˆæ—¶é—´ç­‰æŒ‡æ ‡

---

## ğŸ”´ æ–‡ä»¶ 2: `ai/deepseek_client.py`

### Critical é—®é¢˜

#### 1. API å¯†é’¥å¯èƒ½æ³„éœ² (Line 106, 120)
**ä¸¥é‡ç¨‹åº¦**: ğŸ”´ Critical  
**é—®é¢˜**: API å¯†é’¥å¯èƒ½é€šè¿‡æ—¥å¿—æˆ–å¼‚å¸¸å †æ ˆæ³„éœ²

**å½“å‰ä»£ç **:
```python
self._api_key = self.config.api_key or os.environ.get("DEEPSEEK_API_KEY")
# ...
headers={
    "Authorization": f"Bearer {self._api_key}",
    "Content-Type": "application/json"
}
```

**é—®é¢˜**:
- å¦‚æœ HTTP è¯·æ±‚å¤±è´¥ï¼Œå¼‚å¸¸å¯èƒ½åŒ…å« headersï¼ˆåŒ…å« API keyï¼‰
- æ—¥å¿—ä¸­å¯èƒ½è®°å½•åŒ…å« API key çš„ä¿¡æ¯

**ä¿®å¤å»ºè®®**:
```python
class DeepSeekClient:
    def __init__(self, config: Optional[DeepSeekConfig] = None):
        self.config = config or DeepSeekConfig()
        
        # Get API key from config or environment
        self._api_key = self.config.api_key or os.environ.get("DEEPSEEK_API_KEY")
        if not self._api_key:
            logger.warning("DeepSeek API key not set. AI analysis will be unavailable.")
        else:
            # Log that key is set, but not the key itself
            logger.info("DeepSeekClient initialized (API key set)")
        
        self._client: Optional[httpx.AsyncClient] = None
    
    def __repr__(self) -> str:
        """Safe representation without API key."""
        return f"DeepSeekClient(model={self.config.model})"
    
    async def _get_client(self) -> httpx.AsyncClient:
        """Get or create HTTP client."""
        if self._client is None:
            # Create client with safe error handling
            self._client = httpx.AsyncClient(
                timeout=self.config.timeout_seconds,
                headers={
                    "Authorization": f"Bearer {self._api_key}",
                    "Content-Type": "application/json"
                }
            )
        return self._client
    
    async def analyze_stock(self, ...):
        try:
            # ...
        except httpx.HTTPStatusError as e:
            # Don't log request/response details that might contain API key
            logger.error(f"DeepSeek API HTTP error for {symbol}: {e.response.status_code}")
            # ...
        except Exception as e:
            # Log error but not request details
            logger.error(f"DeepSeek API error for {symbol}: {type(e).__name__}")
            # ...
```

#### 2. HTTP å®¢æˆ·ç«¯ç”Ÿå‘½å‘¨æœŸç®¡ç†ä¸å®Œæ•´ (Line 114-124, 126-130)
**ä¸¥é‡ç¨‹åº¦**: ğŸ”´ Critical  
**é—®é¢˜**: 
- `_get_client()` åˆ›å»ºå®¢æˆ·ç«¯ï¼Œä½†æ²¡æœ‰ç¡®ä¿åœ¨å¼‚å¸¸æ—¶å…³é—­
- `close()` æ–¹æ³•å­˜åœ¨ï¼Œä½†æ²¡æœ‰ Context Manager æ”¯æŒ
- å¦‚æœå®¢æˆ·ç«¯åˆ›å»ºåå‘ç”Ÿå¼‚å¸¸ï¼Œå¯èƒ½æ³„æ¼è¿æ¥

**å½“å‰ä»£ç **:
```python
async def _get_client(self) -> httpx.AsyncClient:
    """Get or create HTTP client."""
    if self._client is None:
        self._client = httpx.AsyncClient(...)
    return self._client

async def close(self):
    """Close HTTP client."""
    if self._client:
        await self._client.aclose()
        self._client = None
```

**ä¿®å¤å»ºè®®**:
```python
async def __aenter__(self):
    """Async context manager entry."""
    return self

async def __aexit__(self, exc_type, exc_val, exc_tb):
    """Async context manager exit - ensures cleanup."""
    await self.close()
    return False

async def _get_client(self) -> httpx.AsyncClient:
    """Get or create HTTP client."""
    if self._client is None or self._client.is_closed:
        # Close old client if exists but closed
        if self._client and self._client.is_closed:
            self._client = None
        
        if self._client is None:
            try:
                self._client = httpx.AsyncClient(
                    timeout=self.config.timeout_seconds,
                    headers={
                        "Authorization": f"Bearer {self._api_key}",
                        "Content-Type": "application/json"
                    }
                )
            except Exception as e:
                logger.error(f"Failed to create HTTP client: {e}")
                raise
    return self._client

async def close(self):
    """Close HTTP client."""
    if self._client and not self._client.is_closed:
        try:
            await self._client.aclose()
        except Exception as e:
            logger.warning(f"Error closing HTTP client: {e}")
        finally:
            self._client = None
```

### Warning é—®é¢˜

#### 3. JSON å“åº”è§£æä¸å¤Ÿå¥å£® (Line 236-284)
**ä¸¥é‡ç¨‹åº¦**: âš ï¸ Warning  
**é—®é¢˜**: 
- JSON è§£æå¤±è´¥æ—¶ä½¿ç”¨ç®€å•çš„æ–‡æœ¬åŒ¹é…ï¼Œå¯èƒ½è¯¯åˆ¤
- æ²¡æœ‰éªŒè¯è§£æå‡ºçš„æ•°æ®æ ¼å¼

**ä¿®å¤å»ºè®®**:
```python
def _parse_response(self, symbol: str, content: str) -> AIAnalysisResult:
    """Parse AI response into structured result."""
    try:
        # Try to extract JSON from response
        content = content.strip()
        
        # Handle markdown code blocks
        if content.startswith("```"):
            # Try to find JSON block
            import re
            json_match = re.search(r'```(?:json)?\s*(\{.*?\})\s*```', content, re.DOTALL)
            if json_match:
                content = json_match.group(1)
            else:
                # Fallback: remove first and last lines
                lines = content.split("\n")
                if len(lines) > 2:
                    content = "\n".join(lines[1:-1])
        
        data = json.loads(content)
        
        # Validate required fields
        recommendation = data.get("recommendation", "hold")
        if recommendation not in ["strong_buy", "buy", "hold", "avoid"]:
            logger.warning(f"Invalid recommendation '{recommendation}' for {symbol}, defaulting to 'hold'")
            recommendation = "hold"
        
        confidence = float(data.get("confidence", 0.5))
        confidence = max(0.0, min(1.0, confidence))  # Clamp to [0, 1]
        
        return AIAnalysisResult(
            symbol=symbol,
            recommendation=recommendation,
            confidence=confidence,
            reasoning=data.get("reasoning", ""),
            key_factors=data.get("key_factors", []),
            risk_factors=data.get("risk_factors", []),
            target_price=data.get("target_price"),
            stop_loss_price=data.get("stop_loss_price")
        )
        
    except json.JSONDecodeError as e:
        logger.warning(f"Failed to parse JSON response for {symbol}: {e}")
        logger.debug(f"Response content: {content[:500]}")
        # Fallback logic...
```

#### 4. æ‰¹é‡åˆ†æç¼ºå°‘é”™è¯¯å¤„ç† (Line 316)
**ä¸¥é‡ç¨‹åº¦**: âš ï¸ Warning  
**é—®é¢˜**: `asyncio.gather(..., return_exceptions=True)` ä¼šè¿”å›å¼‚å¸¸å¯¹è±¡ï¼Œä½†å¤„ç†ä¸å¤Ÿç»†è‡´

**ä¿®å¤å»ºè®®**: åŒºåˆ†ä¸åŒç±»å‹çš„å¼‚å¸¸ï¼Œè®°å½•æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯

#### 5. ç¼ºå°‘è¯·æ±‚é‡è¯•æœºåˆ¶
**ä¸¥é‡ç¨‹åº¦**: âš ï¸ Warning  
**é—®é¢˜**: API è¯·æ±‚å¤±è´¥æ—¶æ²¡æœ‰é‡è¯•

**ä¿®å¤å»ºè®®**: æ·»åŠ æŒ‡æ•°é€€é¿é‡è¯•é€»è¾‘

#### 6. è¶…æ—¶å¤„ç†å¯èƒ½ä¸å¤Ÿ
**ä¸¥é‡ç¨‹åº¦**: âš ï¸ Warning  
**é—®é¢˜**: åªæœ‰ `httpx.TimeoutException` å¤„ç†ï¼Œä½†ç½‘ç»œé”™è¯¯å¯èƒ½è¿˜æœ‰å…¶ä»–ç±»å‹

**ä¿®å¤å»ºè®®**: æ·»åŠ æ›´å…¨é¢çš„å¼‚å¸¸å¤„ç†

### Info é—®é¢˜

#### 7. ç¼ºå°‘è¯·æ±‚é™æµ
**å»ºè®®**: æ·»åŠ è¯·æ±‚é™æµï¼Œé¿å…è¶…è¿‡ API é…é¢

#### 8. ç¼ºå°‘å“åº”ç¼“å­˜
**å»ºè®®**: å¯¹äºç›¸åŒè¾“å…¥ï¼Œå¯ä»¥ç¼“å­˜ AI å“åº”ï¼ˆçŸ­æœŸç¼“å­˜ï¼‰

---

## ğŸ”´ æ–‡ä»¶ 3: `ai/audit.py`

### Critical é—®é¢˜

#### 1. SQL æ³¨å…¥é£é™© (Line 195-199, å…¶ä»–æŸ¥è¯¢)
**ä¸¥é‡ç¨‹åº¦**: ğŸ”´ Critical  
**é—®é¢˜**: è™½ç„¶ä½¿ç”¨äº†å‚æ•°åŒ–æŸ¥è¯¢ï¼Œä½†æŸäº›åœ°æ–¹å¯èƒ½ä»æœ‰é£é™©

**å½“å‰ä»£ç **:
```python
cursor = conn.execute("""
    SELECT * FROM ai_audit 
    WHERE symbol = ?
    ORDER BY timestamp DESC 
    LIMIT ?
""", (symbol, limit))
```

**éªŒè¯**: âœ… ä½¿ç”¨äº†å‚æ•°åŒ–æŸ¥è¯¢ï¼Œè¿™æ˜¯å®‰å…¨çš„ã€‚ä½†éœ€è¦ç¡®ä¿æ‰€æœ‰æŸ¥è¯¢éƒ½ä½¿ç”¨å‚æ•°åŒ–ã€‚

**æ£€æŸ¥ç»“æœ**:
- âœ… Line 126-138: `log_analysis()` ä½¿ç”¨å‚æ•°åŒ–æŸ¥è¯¢
- âœ… Line 160-170: `log_execution()` ä½¿ç”¨å‚æ•°åŒ–æŸ¥è¯¢
- âœ… Line 178-182: `get_recent()` ä½¿ç”¨å‚æ•°åŒ–æŸ¥è¯¢
- âœ… Line 194-199: `get_by_symbol()` ä½¿ç”¨å‚æ•°åŒ–æŸ¥è¯¢
- âœ… Line 265-269: `cleanup_old()` ä½¿ç”¨å‚æ•°åŒ–æŸ¥è¯¢

**ç»“è®º**: SQL æ³¨å…¥é£é™©å·²é€šè¿‡å‚æ•°åŒ–æŸ¥è¯¢æ¶ˆé™¤ âœ…

### Warning é—®é¢˜

#### 2. æ•°æ®åº“è¿æ¥ç®¡ç† (Line 76, 125, 160, 176, 192, 209, 264)
**ä¸¥é‡ç¨‹åº¦**: âš ï¸ Warning  
**é—®é¢˜**: æ¯æ¬¡æ“ä½œéƒ½åˆ›å»ºæ–°è¿æ¥ï¼Œæ²¡æœ‰è¿æ¥æ± 

**å½“å‰ä»£ç **:
```python
with sqlite3.connect(self.db_path) as conn:
    # ...
```

**é—®é¢˜**: 
- SQLite è™½ç„¶æ”¯æŒå¤šè¿æ¥ï¼Œä½†é¢‘ç¹åˆ›å»ºè¿æ¥å¯èƒ½æœ‰æ€§èƒ½é—®é¢˜
- æ²¡æœ‰è¿æ¥æ± ï¼Œé«˜å¹¶å‘æ—¶å¯èƒ½æœ‰é—®é¢˜

**ä¿®å¤å»ºè®®**:
```python
import sqlite3
from contextlib import contextmanager

class AIAudit:
    def __init__(self, db_path: str = "./quant_data/ai_audit.db"):
        self.db_path = Path(db_path)
        self.db_path.parent.mkdir(parents=True, exist_ok=True)
        
        # Connection pool (SQLite supports multiple connections)
        self._connection_pool: List[sqlite3.Connection] = []
        self._max_pool_size = 5
        
        self._init_db()
        logger.info(f"AIAudit initialized at {self.db_path}")
    
    @contextmanager
    def _get_connection(self):
        """Get a database connection from pool or create new one."""
        conn = None
        try:
            if self._connection_pool:
                conn = self._connection_pool.pop()
            else:
                conn = sqlite3.connect(self.db_path, check_same_thread=False)
                conn.row_factory = sqlite3.Row
            
            yield conn
            conn.commit()
        except Exception as e:
            if conn:
                conn.rollback()
            raise
        finally:
            if conn:
                # Return to pool if not full
                if len(self._connection_pool) < self._max_pool_size:
                    self._connection_pool.append(conn)
                else:
                    conn.close()
    
    def log_analysis(self, ...):
        with self._get_connection() as conn:
            cursor = conn.execute(...)
            # ...
```

**æˆ–è€…æ›´ç®€å•çš„æ–¹æ¡ˆ**ï¼ˆSQLite æœ¬èº«æ”¯æŒå¤šè¿æ¥ï¼‰:
```python
# ä¿æŒå½“å‰å®ç°ï¼Œä½†æ·»åŠ è¿æ¥é…ç½®ä¼˜åŒ–
def _get_connection(self) -> sqlite3.Connection:
    """Get a database connection with optimized settings."""
    conn = sqlite3.connect(
        self.db_path,
        timeout=5.0,  # Wait up to 5 seconds for lock
        check_same_thread=False  # Allow multi-threaded access
    )
    conn.row_factory = sqlite3.Row
    # Enable WAL mode for better concurrency
    conn.execute("PRAGMA journal_mode=WAL")
    return conn
```

#### 3. JSON åºåˆ—åŒ–å®‰å…¨æ€§ (Line 134-135, 250-251)
**ä¸¥é‡ç¨‹åº¦**: âš ï¸ Warning  
**é—®é¢˜**: JSON åºåˆ—åŒ–æ—¶æ²¡æœ‰éªŒè¯æ•°æ®å¤§å°ï¼Œå¯èƒ½å¯¼è‡´æ•°æ®åº“å­—æ®µæº¢å‡º

**ä¿®å¤å»ºè®®**:
```python
def _serialize_json(self, data: Dict[str, Any], max_size: int = 10000) -> str:
    """Serialize data to JSON with size check."""
    json_str = json.dumps(data, ensure_ascii=False, default=str)
    if len(json_str) > max_size:
        logger.warning(f"JSON data too large ({len(json_str)} bytes), truncating")
        # Truncate or compress
        json_str = json_str[:max_size]
    return json_str
```

#### 4. ç¼ºå°‘äº‹åŠ¡ç®¡ç†
**ä¸¥é‡ç¨‹åº¦**: âš ï¸ Warning  
**é—®é¢˜**: è™½ç„¶ä½¿ç”¨äº† `with` è¯­å¥ï¼ˆè‡ªåŠ¨æäº¤ï¼‰ï¼Œä½†æ²¡æœ‰æ˜¾å¼äº‹åŠ¡æ§åˆ¶

**ä¿®å¤å»ºè®®**: å¯¹äºæ‰¹é‡æ“ä½œï¼Œä½¿ç”¨æ˜¾å¼äº‹åŠ¡

### Info é—®é¢˜

#### 5. ç¼ºå°‘æ•°æ®å¤‡ä»½æœºåˆ¶
**å»ºè®®**: å®šæœŸå¤‡ä»½å®¡è®¡æ•°æ®åº“

#### 6. ç¼ºå°‘æ•°æ®å‹ç¼©
**å»ºè®®**: å¯¹äºå†å²æ•°æ®ï¼Œå¯ä»¥è€ƒè™‘å‹ç¼©å­˜å‚¨

---

## ğŸ“Š æ€»ä½“å»ºè®®

### 1. æ·»åŠ å•å…ƒæµ‹è¯•
**ä¼˜å…ˆçº§**: ğŸ”´ Critical  
**å»ºè®®**: ä¸ºæ¯ä¸ªæ¨¡å—æ·»åŠ  pytest å•å…ƒæµ‹è¯•

```python
# tests/test_realtime_engine.py
import pytest
import asyncio
from signal_api.core.quant.engines.realtime import RealtimeEngine, RealtimeConfig, EngineMode

@pytest.mark.asyncio
async def test_engine_start_stop():
    """Test engine can start and stop gracefully."""
    engine = RealtimeEngine(RealtimeConfig(mode=EngineMode.SIMULATION))
    # ...
```

### 2. æ·»åŠ é›†æˆæµ‹è¯•
**ä¼˜å…ˆçº§**: âš ï¸ Warning  
**å»ºè®®**: æ·»åŠ ç«¯åˆ°ç«¯çš„å®ç›˜å¼•æ“æµ‹è¯•

### 3. æ€§èƒ½ç›‘æ§
**ä¼˜å…ˆçº§**: â„¹ï¸ Info  
**å»ºè®®**: 
- æ·»åŠ  tick å»¶è¿Ÿç›‘æ§
- æ·»åŠ  API è°ƒç”¨å»¶è¿Ÿç›‘æ§
- æ·»åŠ æ•°æ®åº“æ“ä½œæ€§èƒ½ç›‘æ§

---

## âœ… ç¬¦åˆé¡¹ï¼ˆä¼˜ç‚¹ï¼‰

1. **ä»£ç ç»“æ„æ¸…æ™°**: æ¨¡å—èŒè´£åˆ’åˆ†æ˜ç¡®
2. **å¼‚æ­¥è®¾è®¡**: ä½¿ç”¨ asyncio è¿›è¡Œå¼‚æ­¥æ“ä½œ
3. **é”™è¯¯å¤„ç†**: å¤§éƒ¨åˆ†åœ°æ–¹éƒ½æœ‰å¼‚å¸¸å¤„ç†
4. **æ—¥å¿—è®°å½•**: å…³é”®æ“ä½œéƒ½æœ‰æ—¥å¿—

---

## ğŸ¯ ä¿®å¤ä¼˜å…ˆçº§å»ºè®®

### ç«‹å³ä¿®å¤ (P0)
1. å¼‚æ­¥å¾ªç¯å–æ¶ˆå¤„ç† (`realtime.py`)
2. API å¯†é’¥æ³„éœ²é£é™© (`deepseek_client.py`)
3. HTTP å®¢æˆ·ç«¯ç”Ÿå‘½å‘¨æœŸç®¡ç† (`deepseek_client.py`)
4. äº¤æ˜“æ—¶æ®µæ£€æµ‹é€»è¾‘ (`realtime.py`)

### å°½å¿«ä¿®å¤ (P1)
1. æ­¢æŸæ‰§è¡Œæ—¶æœº (`realtime.py`)
2. JSON å“åº”è§£æ (`deepseek_client.py`)
3. æ•°æ®åº“è¿æ¥ç®¡ç† (`audit.py`)
4. ç¼ºå°‘ Context Manager (`realtime.py`, `deepseek_client.py`)

### è®¡åˆ’ä¿®å¤ (P2)
1. æ·»åŠ å•å…ƒæµ‹è¯•
2. æ·»åŠ é‡è¯•æœºåˆ¶
3. æ·»åŠ æ€§èƒ½ç›‘æ§

---

## ğŸ“ æ€»ç»“

æ•´ä½“ä»£ç è´¨é‡**è‰¯å¥½**ï¼Œä½†å­˜åœ¨ä¸€äº›**å…³é”®çš„å¼‚æ­¥å®‰å…¨å’Œèµ„æºç®¡ç†é—®é¢˜**éœ€è¦ç«‹å³ä¿®å¤ã€‚ä¸»è¦é—®é¢˜é›†ä¸­åœ¨ï¼š

1. **å¼‚æ­¥å®‰å…¨**: å¾ªç¯å–æ¶ˆã€èµ„æºæ¸…ç†
2. **èµ„æºç®¡ç†**: HTTP å®¢æˆ·ç«¯ã€æ•°æ®åº“è¿æ¥
3. **å®‰å…¨æ€§**: API å¯†é’¥å¤„ç†
4. **é”™è¯¯å¤„ç†**: éœ€è¦æ›´å®Œå–„çš„å¼‚å¸¸å¤„ç†

å»ºè®®æŒ‰ç…§ä¼˜å…ˆçº§é€æ­¥ä¿®å¤ï¼Œå¹¶åœ¨ä¿®å¤åæ·»åŠ ç›¸åº”çš„å•å…ƒæµ‹è¯•ã€‚

---

**å®¡æŸ¥å®Œæˆæ—¶é—´**: 2025-01-XX  
**ä¸‹æ¬¡å®¡æŸ¥å»ºè®®**: ä¿®å¤ Critical é—®é¢˜åè¿›è¡Œå›å½’å®¡æŸ¥

