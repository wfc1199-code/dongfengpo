# Phase 5 å®ç°è®¡åˆ’å®¡æŸ¥æŠ¥å‘Š

**å®¡æŸ¥æ—¥æœŸ**: 2025-01-XX  
**å®¡æŸ¥èŒƒå›´**: Phase 5 å®ç°è®¡åˆ’ï¼ˆAPI è·¯ç”±ã€DataManagerã€å®šæ—¶ä»»åŠ¡ã€æ•°æ®æ ¡éªŒã€é™æµé…ç½®ï¼‰  
**å®¡æŸ¥ç»´åº¦**: æ¶æ„è®¾è®¡ã€API è®¾è®¡ã€æ•°æ®ä¸€è‡´æ€§ã€æ€§èƒ½ä¸é™æµã€å¯ç»´æŠ¤æ€§

---

## ğŸ“‹ å®¡æŸ¥æ¦‚è§ˆ

| æ¨¡å— | è®¾è®¡å®Œæ•´æ€§ | æŠ€æœ¯å¯è¡Œæ€§ | é£é™©è¯„ä¼° | æ€»ä½“è¯„åˆ† |
|------|-----------|-----------|----------|----------|
| API è·¯ç”±è®¾è®¡ (6ä¸ªç«¯ç‚¹) | âš ï¸ éœ€è¡¥å…… | âœ… å¯è¡Œ | âš ï¸ ä¸­ç­‰ | âš ï¸ éœ€æ”¹è¿› |
| DataManager ç»Ÿä¸€å…¥å£ | âœ… è‰¯å¥½ | âœ… å¯è¡Œ | âœ… ä½ | âœ… è‰¯å¥½ |
| å®šæ—¶ä»»åŠ¡ (16:30) | âš ï¸ éœ€è¡¥å…… | âœ… å¯è¡Œ | âš ï¸ ä¸­ç­‰ | âš ï¸ éœ€æ”¹è¿› |
| æ•°æ®æ ¡éªŒ (240 Kçº¿) | âœ… è‰¯å¥½ | âœ… å¯è¡Œ | âœ… ä½ | âœ… è‰¯å¥½ |
| é™æµé…ç½® (400/min + 150ms) | âš ï¸ éœ€è¡¥å…… | âœ… å¯è¡Œ | âš ï¸ ä¸­ç­‰ | âš ï¸ éœ€æ”¹è¿› |

**æ€»ä½“è¯„ä¼°**: âš ï¸ **éœ€è¡¥å……ç»†èŠ‚** - æ ¸å¿ƒæ€è·¯æ­£ç¡®ï¼Œä½†éœ€è¦å®Œå–„è®¾è®¡ç»†èŠ‚

---

## ğŸ” è¯¦ç»†å®¡æŸ¥

### 1. API è·¯ç”±è®¾è®¡ï¼ˆ6ä¸ªç«¯ç‚¹ï¼‰

#### å½“å‰çŠ¶æ€
**é—®é¢˜**: æœªæ˜ç¡®è¯´æ˜ 6 ä¸ªç«¯ç‚¹çš„å…·ä½“å®šä¹‰

#### å»ºè®®çš„ç«¯ç‚¹è®¾è®¡

åŸºäº Phase 1-4 çš„å®ç°ï¼Œå»ºè®®ä»¥ä¸‹ 6 ä¸ªç«¯ç‚¹ï¼š

```python
# services/signal-api/signal_api/routers/quant.py

router = APIRouter(prefix="/api/quant", tags=["quant"])

# 1. è·å–ç­–ç•¥ä¿¡å·åˆ—è¡¨
@router.get("/signals")
async def list_signals(
    strategy: Optional[str] = None,
    symbol: Optional[str] = None,
    limit: int = 50
) -> List[SignalResponse]:
    """è·å–ç­–ç•¥ä¿¡å·åˆ—è¡¨"""
    pass

# 2. è·å–æŒä»“çŠ¶æ€
@router.get("/positions")
async def get_positions() -> List[PositionResponse]:
    """è·å–å½“å‰æŒä»“çŠ¶æ€"""
    pass

# 3. è·å–é£æ§çŠ¶æ€
@router.get("/risk/status")
async def get_risk_status() -> RiskStatusResponse:
    """è·å–é£æ§çŠ¶æ€ï¼ˆèµ„é‡‘ã€å›æ’¤ã€ç†”æ–­ç­‰ï¼‰"""
    pass

# 4. è·å–å›æµ‹ç»“æœ
@router.get("/backtest/results")
async def get_backtest_results(
    strategy: str,
    start_date: str,
    end_date: str
) -> BacktestResultResponse:
    """è·å–å›æµ‹ç»“æœ"""
    pass

# 5. è·å–æ˜æ—¥æ± ï¼ˆæ½œä¼ç­–ç•¥ï¼‰
@router.get("/ambush/pool")
async def get_ambush_pool() -> List[AmbushCandidateResponse]:
    """è·å–æ½œä¼ç­–ç•¥çš„æ˜æ—¥æ± """
    pass

# 6. è·å– AI åˆ†æç»“æœ
@router.get("/ai/analysis/{symbol}")
async def get_ai_analysis(symbol: str) -> AIAnalysisResponse:
    """è·å–æŒ‡å®šè‚¡ç¥¨çš„ AI åˆ†æç»“æœ"""
    pass
```

#### å®¡æŸ¥æ„è§

**ä¼˜ç‚¹**:
- âœ… ç«¯ç‚¹è®¾è®¡ç¬¦åˆ RESTful è§„èŒƒ
- âœ… ä½¿ç”¨ FastAPI çš„ä¾èµ–æ³¨å…¥æ¨¡å¼
- âœ… æ”¯æŒæŸ¥è¯¢å‚æ•°è¿‡æ»¤

**é—®é¢˜**:
- âŒ **ç¼ºå°‘ç«¯ç‚¹å®šä¹‰æ–‡æ¡£**: éœ€è¦æ˜ç¡®è¯´æ˜æ¯ä¸ªç«¯ç‚¹çš„ç”¨é€”ã€å‚æ•°ã€è¿”å›å€¼
- âŒ **ç¼ºå°‘é”™è¯¯å¤„ç†**: éœ€è¦å®šä¹‰ç»Ÿä¸€çš„é”™è¯¯å“åº”æ ¼å¼
- âŒ **ç¼ºå°‘è®¤è¯æˆæƒ**: å®ç›˜æ¥å£éœ€è¦è®¤è¯æœºåˆ¶
- âŒ **ç¼ºå°‘ç‰ˆæœ¬æ§åˆ¶**: å»ºè®®ä½¿ç”¨ `/api/v1/quant` å‰ç¼€

**ä¿®å¤å»ºè®®**:
1. è¡¥å…… OpenAPI æ–‡æ¡£ï¼ˆFastAPI è‡ªåŠ¨ç”Ÿæˆï¼Œä½†éœ€è¦å®Œå–„æè¿°ï¼‰
2. å®šä¹‰ç»Ÿä¸€çš„å“åº”æ¨¡å‹ï¼š
   ```python
   @dataclass
   class APIResponse:
       success: bool
       data: Any
       error: Optional[str] = None
       timestamp: datetime = field(default_factory=datetime.now)
   ```
3. æ·»åŠ è®¤è¯ä¸­é—´ä»¶ï¼ˆJWT æˆ– API Keyï¼‰
4. æ·»åŠ è¯·æ±‚é™æµï¼ˆè§é™æµé…ç½®éƒ¨åˆ†ï¼‰

---

### 2. DataManager ç»Ÿä¸€æ•°æ®å…¥å£

#### å½“å‰çŠ¶æ€
**å·²æœ‰å®ç°**: `services/signal-api/signal_api/data/data_sources.py` ä¸­çš„ `StockDataManager`

#### å®¡æŸ¥æ„è§

**ä¼˜ç‚¹**:
- âœ… å·²æœ‰ç»Ÿä¸€æ•°æ®æºå®ç°
- âœ… æ”¯æŒå¤šæº Fallbackï¼ˆè…¾è®¯ã€ä¸œè´¢ã€AkShareï¼‰
- âœ… æœ‰ç¼“å­˜æœºåˆ¶

**é—®é¢˜**:
- âš ï¸ **ä¸ Quant æ¨¡å—é›†æˆ**: éœ€è¦ç¡®è®¤ DataManager æ˜¯å¦ä¸ DuckDB æ•°æ®å±‚é›†æˆ
- âš ï¸ **æ•°æ®ä¸€è‡´æ€§**: éœ€è¦ç¡®ä¿å®æ—¶æ•°æ®å’Œå†å²æ•°æ®çš„ä¸€è‡´æ€§
- âš ï¸ **é”™è¯¯å¤„ç†**: éœ€è¦ç»Ÿä¸€çš„é”™è¯¯å¤„ç†æœºåˆ¶

**ä¿®å¤å»ºè®®**:
```python
# services/signal-api/signal_api/core/quant/data/manager.py

class QuantDataManager:
    """ç»Ÿä¸€æ•°æ®å…¥å£ï¼Œæ•´åˆå®æ—¶æ•°æ®å’Œå†å²æ•°æ®"""
    
    def __init__(
        self,
        duckdb_manager: DuckDBManager,
        realtime_source: StockDataManager,
        validator: DataValidator
    ):
        self.duckdb = duckdb_manager
        self.realtime = realtime_source
        self.validator = validator
    
    async def get_minute_data(
        self,
        symbol: str,
        start_date: Optional[datetime] = None,
        end_date: Optional[datetime] = None
    ) -> pd.DataFrame:
        """è·å–åˆ†é’Ÿçº¿æ•°æ®ï¼ˆä¼˜å…ˆä» DuckDBï¼Œç¼ºå¤±åˆ™ä»å®æ—¶æºè¡¥å……ï¼‰"""
        # 1. ä» DuckDB è¯»å–å†å²æ•°æ®
        df = self.duckdb.load_minute_data(symbol, start_date, end_date)
        
        # 2. å¦‚æœç¼ºå¤±æœ€æ–°æ•°æ®ï¼Œä»å®æ—¶æºè¡¥å……
        if end_date and end_date > datetime.now() - timedelta(minutes=5):
            realtime_data = await self.realtime.get_minute_data(symbol)
            df = pd.concat([df, realtime_data]).drop_duplicates('datetime')
        
        # 3. æ•°æ®æ ¡éªŒ
        is_valid, errors = self.validator.validate(df, symbol)
        if not is_valid:
            logger.warning(f"Data validation failed for {symbol}: {errors}")
        
        return df
```

---

### 3. å®šæ—¶ä»»åŠ¡ï¼ˆ16:30 æ”¶ç›˜åŒæ­¥ï¼‰

#### å½“å‰çŠ¶æ€
**é—®é¢˜**: æœªæ˜ç¡®è¯´æ˜å®šæ—¶ä»»åŠ¡çš„å®ç°æ–¹å¼

#### å®¡æŸ¥æ„è§

**å»ºè®®å®ç°æ–¹æ¡ˆ**:

**æ–¹æ¡ˆ 1: APScheduler (æ¨è)**
```python
# services/signal-api/signal_api/core/quant/scheduler.py

from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.triggers.cron import CronTrigger

class QuantScheduler:
    def __init__(self, downloader: DataDownloader):
        self.scheduler = AsyncIOScheduler()
        self.downloader = downloader
    
    def start(self):
        # æ¯æ—¥ 16:30 æ”¶ç›˜ååŒæ­¥æ•°æ®
        self.scheduler.add_job(
            self._sync_daily_data,
            trigger=CronTrigger(hour=16, minute=30),
            id='daily_sync',
            replace_existing=True
        )
        
        # æ¯æ—¥ 09:00 å¼€ç›˜å‰æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
        self.scheduler.add_job(
            self._check_data_integrity,
            trigger=CronTrigger(hour=9, minute=0),
            id='morning_check',
            replace_existing=True
        )
        
        self.scheduler.start()
    
    async def _sync_daily_data(self):
        """æ”¶ç›˜ååŒæ­¥å½“æ—¥æ•°æ®"""
        logger.info("Starting daily data sync at 16:30")
        try:
            # 1. ä¸‹è½½å½“æ—¥åˆ†é’Ÿçº¿æ•°æ®
            await self.downloader.download_minute_data(
                date=datetime.now().date()
            )
            
            # 2. éªŒè¯æ•°æ®å®Œæ•´æ€§ï¼ˆ240 æ ¹ K çº¿ï¼‰
            # 3. å¤‡ä»½åˆ° backup/ ç›®å½•
            # 4. æ›´æ–° SQLite å…ƒæ•°æ®
            
        except Exception as e:
            logger.error(f"Daily sync failed: {e}")
            # å‘é€å‘Šè­¦é€šçŸ¥
    
    async def _check_data_integrity(self):
        """å¼€ç›˜å‰æ£€æŸ¥æ•°æ®å®Œæ•´æ€§"""
        # æ£€æŸ¥æ˜¨æ—¥æ•°æ®æ˜¯å¦å®Œæ•´
        pass
```

**æ–¹æ¡ˆ 2: Celery Beat (å¦‚æœå·²æœ‰ Celery)**
```python
# ä½¿ç”¨ Celery Beat å®šæ—¶ä»»åŠ¡
@celery_app.task
def sync_daily_data():
    # åŒæ­¥é€»è¾‘
    pass

# celerybeat_schedule
CELERYBEAT_SCHEDULE = {
    'daily-sync': {
        'task': 'sync_daily_data',
        'schedule': crontab(hour=16, minute=30),
    },
}
```

**é—®é¢˜**:
- âš ï¸ **æ—¶åŒºå¤„ç†**: éœ€è¦æ˜ç¡®ä½¿ç”¨å“ªä¸ªæ—¶åŒºï¼ˆå»ºè®®ä½¿ç”¨ Asia/Shanghaiï¼‰
- âš ï¸ **å¤±è´¥é‡è¯•**: éœ€è¦å®ç°å¤±è´¥é‡è¯•æœºåˆ¶
- âš ï¸ **ä»»åŠ¡ç›‘æ§**: éœ€è¦è®°å½•ä»»åŠ¡æ‰§è¡ŒçŠ¶æ€å’Œæ—¥å¿—

**ä¿®å¤å»ºè®®**:
1. ä½¿ç”¨ `pytz` å¤„ç†æ—¶åŒºï¼š
   ```python
   import pytz
   tz = pytz.timezone('Asia/Shanghai')
   trigger = CronTrigger(hour=16, minute=30, timezone=tz)
   ```
2. å®ç°é‡è¯•æœºåˆ¶ï¼š
   ```python
   from tenacity import retry, stop_after_attempt, wait_exponential
   
   @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))
   async def _sync_daily_data(self):
       # åŒæ­¥é€»è¾‘
       pass
   ```
3. æ·»åŠ ä»»åŠ¡çŠ¶æ€è®°å½•ï¼ˆSQLite æˆ– Redisï¼‰

---

### 4. æ•°æ®æ ¡éªŒï¼ˆ240 æ ¹ K çº¿å®Œæ•´æ€§æ£€æŸ¥ï¼‰

#### å½“å‰çŠ¶æ€
**å·²æœ‰å®ç°**: `services/signal-api/signal_api/core/quant/data/validator.py`

#### å®¡æŸ¥æ„è§

**ä¼˜ç‚¹**:
- âœ… å·²æœ‰ `DataValidator` ç±»å®ç°
- âœ… åŒ…å«å®Œæ•´æ€§æ£€æŸ¥ï¼ˆ`_check_completeness`ï¼‰
- âœ… æ”¯æŒä¸¥æ ¼æ¨¡å¼å’Œå®½æ¾æ¨¡å¼

**éªŒè¯ä»£ç **:
```python
# services/signal-api/signal_api/core/quant/data/validator.py:107-130

def _check_completeness(self, df: pd.DataFrame, symbol: str):
    """Check if each trading day has expected number of bars."""
    df['date'] = df['datetime'].dt.date
    daily_counts = df.groupby('date').size()
    
    for date, count in daily_counts.items():
        if count < self.EXPECTED_BARS_MIN:
            self._add_error(
                symbol,
                "INCOMPLETE_DATA",
                f"Date {date} has only {count} bars, expected {self.EXPECTED_BARS_MIN}",
                {"date": str(date), "count": count, "expected": self.EXPECTED_BARS_MIN}
            )
```

**é—®é¢˜**:
- âš ï¸ **æ ¡éªŒæ—¶æœº**: éœ€è¦æ˜ç¡®åœ¨å“ªäº›ç¯èŠ‚è¿›è¡Œæ ¡éªŒ
  - æ•°æ®ä¸‹è½½åï¼Ÿ
  - æ•°æ®å­˜å‚¨å‰ï¼Ÿ
  - æ•°æ®è¯»å–åï¼Ÿ
- âš ï¸ **æ ¡éªŒç»“æœå¤„ç†**: æ ¡éªŒå¤±è´¥åçš„å¤„ç†ç­–ç•¥ï¼ˆæ‹’ç»ã€è­¦å‘Šã€è‡ªåŠ¨ä¿®å¤ï¼‰

**ä¿®å¤å»ºè®®**:
```python
# åœ¨ DataDownloader ä¸­é›†æˆæ ¡éªŒ
class DataDownloader:
    async def download_and_validate(self, symbol: str, date: date):
        # 1. ä¸‹è½½æ•°æ®
        df = await self._download(symbol, date)
        
        # 2. æ ¡éªŒæ•°æ®
        validator = DataValidator(strict_mode=False)  # å®½æ¾æ¨¡å¼ï¼Œè®°å½•é”™è¯¯ä½†ä¸ä¸­æ–­
        is_valid, errors = validator.validate(df, symbol)
        
        # 3. å¦‚æœæ ¡éªŒå¤±è´¥ï¼Œå°è¯•è¡¥å½•
        if not is_valid:
            logger.warning(f"Validation failed for {symbol} on {date}: {errors}")
            # å°è¯•ä»å…¶ä»–æ•°æ®æºè¡¥å½•ç¼ºå¤±çš„ K çº¿
            df = await self._supplement_missing_bars(df, symbol, date, errors)
        
        # 4. å†æ¬¡æ ¡éªŒ
        is_valid, errors = validator.validate(df, symbol)
        if not is_valid:
            raise DataValidationError(f"Data validation failed after supplement: {errors}")
        
        # 5. å­˜å‚¨æ•°æ®
        await self.duckdb_manager.save_minute_data(symbol, df)
```

---

### 5. é™æµé…ç½®ï¼ˆ400/min + 150ms é—´éš”ï¼‰

#### å½“å‰çŠ¶æ€
**é—®é¢˜**: æœªæ˜ç¡®è¯´æ˜é™æµçš„å…·ä½“å®ç°å’Œé…ç½®ä½ç½®

#### å®¡æŸ¥æ„è§

**å»ºè®®å®ç°æ–¹æ¡ˆ**:

**æ–¹æ¡ˆ 1: SlowAPI (FastAPI é™æµä¸­é—´ä»¶)**
```python
# services/signal-api/signal_api/middleware/rate_limit.py

from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address
from slowapi.errors import RateLimitExceeded

limiter = Limiter(key_func=get_remote_address)

# åœ¨ app.py ä¸­æ³¨å†Œ
app.state.limiter = limiter
app.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)

# åœ¨è·¯ç”±ä¸­ä½¿ç”¨
@router.get("/signals")
@limiter.limit("400/minute")  # 400 æ¬¡/åˆ†é’Ÿ
async def list_signals(request: Request):
    pass
```

**æ–¹æ¡ˆ 2: Redis é™æµï¼ˆåˆ†å¸ƒå¼é™æµï¼‰**
```python
# services/signal-api/signal_api/middleware/rate_limit.py

import redis.asyncio as aioredis
from datetime import datetime, timedelta

class RateLimiter:
    def __init__(self, redis_client: aioredis.Redis):
        self.redis = redis_client
        self.max_requests = 400
        self.window_seconds = 60
        self.min_interval_ms = 150
    
    async def check_rate_limit(self, key: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦è¶…è¿‡é™æµ"""
        # æ»‘åŠ¨çª—å£é™æµ
        now = datetime.now()
        window_start = now - timedelta(seconds=self.window_seconds)
        
        # è·å–çª—å£å†…çš„è¯·æ±‚æ•°
        count = await self.redis.zcount(
            f"rate_limit:{key}",
            window_start.timestamp(),
            now.timestamp()
        )
        
        if count >= self.max_requests:
            return False
        
        # æ£€æŸ¥æœ€å°é—´éš”ï¼ˆ150msï¼‰
        last_request = await self.redis.get(f"rate_limit:last:{key}")
        if last_request:
            last_time = datetime.fromtimestamp(float(last_request))
            if (now - last_time).total_seconds() * 1000 < self.min_interval_ms:
                return False
        
        # è®°å½•æœ¬æ¬¡è¯·æ±‚
        await self.redis.zadd(
            f"rate_limit:{key}",
            {str(now.timestamp()): now.timestamp()}
        )
        await self.redis.setex(
            f"rate_limit:last:{key}",
            1,  # 1 ç§’è¿‡æœŸ
            str(now.timestamp())
        )
        
        return True
```

**é—®é¢˜**:
- âš ï¸ **é™æµç²’åº¦**: éœ€è¦æ˜ç¡®æ˜¯æŒ‰ IPã€æŒ‰ç”¨æˆ·ã€è¿˜æ˜¯å…¨å±€é™æµ
- âš ï¸ **é™æµç­–ç•¥**: 400/min æ˜¯å…¨å±€è¿˜æ˜¯æ¯ä¸ªç«¯ç‚¹ï¼Ÿ
- âš ï¸ **150ms é—´éš”**: æ˜¯æ¯ä¸ªè¯·æ±‚ä¹‹é—´çš„æœ€å°é—´éš”ï¼Œè¿˜æ˜¯ç‰¹å®šæ“ä½œçš„é—´éš”ï¼Ÿ

**ä¿®å¤å»ºè®®**:
1. **åˆ†å±‚é™æµ**:
   ```python
   # å…¨å±€é™æµ: 400/min
   @limiter.limit("400/minute")
   
   # å•ç«¯ç‚¹é™æµ: æ›´ä¸¥æ ¼çš„é™åˆ¶
   @router.get("/ai/analysis/{symbol}")
   @limiter.limit("10/minute")  # AI åˆ†ææ›´è€—èµ„æº
   async def get_ai_analysis(symbol: str):
       pass
   ```

2. **150ms é—´éš”å®ç°**:
   ```python
   # åœ¨ DataManager ä¸­å®ç°è¯·æ±‚é—´éš”
   class DataManager:
       def __init__(self):
           self._last_request_time = 0
           self._min_interval_ms = 150
       
       async def _throttle_request(self):
           """ç¡®ä¿è¯·æ±‚é—´éš” >= 150ms"""
           now_ms = time.time() * 1000
           elapsed = now_ms - self._last_request_time
           if elapsed < self._min_interval_ms:
               await asyncio.sleep((self._min_interval_ms - elapsed) / 1000)
           self._last_request_time = time.time() * 1000
   ```

3. **é…ç½®åŒ–é™æµ**:
   ```python
   # config/rate_limit.json
   {
     "global": {
       "max_requests_per_minute": 400,
       "min_interval_ms": 150
     },
     "endpoints": {
       "/api/quant/signals": {
         "max_requests_per_minute": 200
       },
       "/api/quant/ai/analysis": {
         "max_requests_per_minute": 10,
         "min_interval_ms": 1000
       }
     }
   }
   ```

---

## ğŸ“Š æ€»ä½“å»ºè®®

### 1. ç«‹å³è¡¥å…… (P0)
1. âœ… **æ˜ç¡® 6 ä¸ª API ç«¯ç‚¹çš„å®šä¹‰**: ç”¨é€”ã€å‚æ•°ã€è¿”å›å€¼ã€é”™è¯¯ç 
2. âœ… **æ˜ç¡®å®šæ—¶ä»»åŠ¡çš„å®ç°æ–¹å¼**: APScheduler è¿˜æ˜¯ Celery Beat
3. âœ… **æ˜ç¡®é™æµé…ç½®çš„ç²’åº¦**: å…¨å±€è¿˜æ˜¯æŒ‰ç«¯ç‚¹

### 2. å°½å¿«å®Œå–„ (P1)
1. âš ï¸ **API æ–‡æ¡£**: è¡¥å…… OpenAPI/Swagger æ–‡æ¡£
2. âš ï¸ **é”™è¯¯å¤„ç†**: å®šä¹‰ç»Ÿä¸€çš„é”™è¯¯å“åº”æ ¼å¼
3. âš ï¸ **è®¤è¯æˆæƒ**: å®ç›˜æ¥å£éœ€è¦è®¤è¯æœºåˆ¶
4. âš ï¸ **ä»»åŠ¡ç›‘æ§**: å®šæ—¶ä»»åŠ¡æ‰§è¡ŒçŠ¶æ€ç›‘æ§

### 3. è®¡åˆ’ä¼˜åŒ– (P2)
1. â„¹ï¸ **æ€§èƒ½ä¼˜åŒ–**: æ•°æ®æŸ¥è¯¢æ€§èƒ½ä¼˜åŒ–
2. â„¹ï¸ **ç›‘æ§å‘Šè­¦**: æ·»åŠ  Prometheus æŒ‡æ ‡
3. â„¹ï¸ **å•å…ƒæµ‹è¯•**: ä¸ºå…³é”®åŠŸèƒ½æ·»åŠ æµ‹è¯•

---

## âœ… ç¬¦åˆé¡¹ï¼ˆä¼˜ç‚¹ï¼‰

1. **æ¶æ„æ€è·¯æ­£ç¡®**: ç»Ÿä¸€æ•°æ®å…¥å£ã€å®šæ—¶åŒæ­¥ã€æ•°æ®æ ¡éªŒçš„æ€è·¯éƒ½å¾ˆå¥½
2. **æŠ€æœ¯é€‰å‹åˆç†**: ä½¿ç”¨ FastAPIã€DuckDBã€APScheduler ç­‰æŠ€æœ¯æ ˆåˆç†
3. **å·²æœ‰åŸºç¡€**: Phase 1-4 å·²ç»å®ç°äº†æ ¸å¿ƒç»„ä»¶ï¼ŒPhase 5 ä¸»è¦æ˜¯æ•´åˆ

---

## ğŸ¯ ä¿®å¤ä¼˜å…ˆçº§å»ºè®®

### ç«‹å³è¡¥å…… (P0)
1. ğŸ”´ æ˜ç¡® 6 ä¸ª API ç«¯ç‚¹çš„å®Œæ•´å®šä¹‰
2. ğŸ”´ æ˜ç¡®å®šæ—¶ä»»åŠ¡çš„å®ç°æ–¹æ¡ˆå’Œæ—¶åŒºå¤„ç†
3. ğŸ”´ æ˜ç¡®é™æµé…ç½®çš„ç²’åº¦å’Œç­–ç•¥

### å°½å¿«å®Œå–„ (P1)
1. âš ï¸ è¡¥å…… API æ–‡æ¡£å’Œé”™è¯¯å¤„ç†
2. âš ï¸ å®ç° DataManager ä¸ Quant æ¨¡å—çš„é›†æˆ
3. âš ï¸ å®Œå–„æ•°æ®æ ¡éªŒçš„å¤±è´¥å¤„ç†ç­–ç•¥

### è®¡åˆ’ä¼˜åŒ– (P2)
1. â„¹ï¸ æ·»åŠ ç›‘æ§å’Œå‘Šè­¦
2. â„¹ï¸ æ€§èƒ½ä¼˜åŒ–å’Œæµ‹è¯•

---

## ğŸ“ æ€»ç»“

Phase 5 å®ç°è®¡åˆ’çš„**æ ¸å¿ƒæ€è·¯æ­£ç¡®**ï¼Œä½†éœ€è¦**è¡¥å……è®¾è®¡ç»†èŠ‚**ã€‚ä¸»è¦é—®é¢˜ï¼š

1. **API ç«¯ç‚¹å®šä¹‰ä¸æ˜ç¡®**: éœ€è¦æ˜ç¡® 6 ä¸ªç«¯ç‚¹çš„å®Œæ•´å®šä¹‰
2. **å®šæ—¶ä»»åŠ¡ç»†èŠ‚ç¼ºå¤±**: éœ€è¦æ˜ç¡®å®ç°æ–¹å¼å’Œæ—¶åŒºå¤„ç†
3. **é™æµé…ç½®ä¸æ¸…æ™°**: éœ€è¦æ˜ç¡®é™æµç²’åº¦å’Œç­–ç•¥

å»ºè®®æŒ‰ç…§ä¼˜å…ˆçº§é€æ­¥å®Œå–„è®¾è®¡æ–‡æ¡£ï¼Œç„¶åå¼€å§‹å®ç°ã€‚

---

**å®¡æŸ¥å®Œæˆæ—¶é—´**: 2025-01-XX  
**ä¸‹æ¬¡å®¡æŸ¥å»ºè®®**: è¡¥å……è®¾è®¡ç»†èŠ‚åè¿›è¡Œè¯¦ç»†è®¾è®¡å®¡æŸ¥

