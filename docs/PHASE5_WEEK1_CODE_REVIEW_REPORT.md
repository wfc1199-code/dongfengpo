# Phase 5 Week 1 ä»£ç å®¡æŸ¥æŠ¥å‘Šï¼šç»Ÿä¸€æ•°æ®å±‚

**å®¡æŸ¥æ—¥æœŸ**: 2025-01-XX  
**å®¡æŸ¥èŒƒå›´**: ç»Ÿä¸€æ•°æ®å±‚å®ç°ï¼ˆ4ä¸ªæ ¸å¿ƒæ–‡ä»¶ï¼‰  
**å®¡æŸ¥ç»´åº¦**: ç®—æ³•æ­£ç¡®æ€§ã€çº¿ç¨‹/å¼‚æ­¥å®‰å…¨ã€èµ„æºç®¡ç†ã€é”™è¯¯å¤„ç†ã€ç±»å‹å®‰å…¨

---

## ğŸ“‹ å®¡æŸ¥æ¦‚è§ˆ

| æ–‡ä»¶ | Critical | Warning | Info | æ€»ä½“è¯„åˆ† |
|------|----------|---------|------|----------|
| `rate_limiter.py` | 1 | 3 | 2 | âš ï¸ éœ€æ”¹è¿› |
| `manager.py` | 2 | 5 | 2 | âš ï¸ éœ€æ”¹è¿› |
| `quant.py` | 2 | 4 | 2 | âš ï¸ éœ€æ”¹è¿› |
| `app.py` | 0 | 0 | 0 | âœ… ä¼˜ç§€ |

**æ€»è®¡**: 5 Critical, 12 Warning, 6 Info

---

## ğŸ”´ æ–‡ä»¶ 1: `rate_limiter.py`

### Critical é—®é¢˜

#### 1. å•ä¾‹æ¨¡å¼çº¿ç¨‹å®‰å…¨é—®é¢˜ (Line 139-147)
**ä¸¥é‡ç¨‹åº¦**: ğŸ”´ Critical  
**é—®é¢˜**: å…¨å±€å•ä¾‹åœ¨å¤šçº¿ç¨‹/å¤šè¿›ç¨‹ç¯å¢ƒä¸‹å¯èƒ½åˆ›å»ºå¤šä¸ªå®ä¾‹

**å½“å‰ä»£ç **:
```python
_global_limiter: Optional[TokenBucketRateLimiter] = None

def get_rate_limiter(config: Optional[RateLimitConfig] = None) -> TokenBucketRateLimiter:
    """Get or create the global rate limiter instance."""
    global _global_limiter
    if _global_limiter is None:
        _global_limiter = TokenBucketRateLimiter(config)
    return _global_limiter
```

**é—®é¢˜**:
- åœ¨ FastAPI çš„å¤š worker ç¯å¢ƒä¸‹ï¼Œæ¯ä¸ª worker éƒ½æœ‰è‡ªå·±çš„è¿›ç¨‹ï¼Œä¼šåˆ›å»ºç‹¬ç«‹çš„å®ä¾‹
- åœ¨å•è¿›ç¨‹å¤šçº¿ç¨‹ç¯å¢ƒä¸‹ï¼Œè™½ç„¶æœ‰ GILï¼Œä½†ç†è®ºä¸Šä»å­˜åœ¨ç«æ€æ¡ä»¶ï¼ˆè™½ç„¶ Python GIL ä¼šä¿æŠ¤ï¼Œä½†æœ€å¥½æ˜¾å¼åŠ é”ï¼‰

**ä¿®å¤å»ºè®®**:
```python
import threading

_global_limiter: Optional[TokenBucketRateLimiter] = None
_limiter_lock = threading.Lock()

def get_rate_limiter(config: Optional[RateLimitConfig] = None) -> TokenBucketRateLimiter:
    """Get or create the global rate limiter instance (thread-safe)."""
    global _global_limiter
    
    # Double-checked locking pattern
    if _global_limiter is None:
        with _limiter_lock:
            if _global_limiter is None:
                _global_limiter = TokenBucketRateLimiter(config)
    
    return _global_limiter
```

**æ³¨æ„**: åœ¨å¤šè¿›ç¨‹ç¯å¢ƒä¸‹ï¼ˆå¦‚ uvicorn workersï¼‰ï¼Œæ¯ä¸ªè¿›ç¨‹ä¼šæœ‰ç‹¬ç«‹çš„é™æµå™¨å®ä¾‹ï¼Œè¿™æ˜¯é¢„æœŸçš„è¡Œä¸ºã€‚å¦‚æœéœ€è¦è·¨è¿›ç¨‹é™æµï¼Œéœ€è¦ä½¿ç”¨ Redis ç­‰å¤–éƒ¨å­˜å‚¨ã€‚

### Warning é—®é¢˜

#### 2. ä»¤ç‰Œæ¡¶ç®—æ³•å®ç°é—®é¢˜ (Line 88-113)
**ä¸¥é‡ç¨‹åº¦**: âš ï¸ Warning  
**é—®é¢˜**: `acquire()` æ–¹æ³•åœ¨é”å†…å¾ªç¯ç­‰å¾…ï¼Œå¯èƒ½å¯¼è‡´æ­»é”æˆ–æ€§èƒ½é—®é¢˜

**å½“å‰ä»£ç **:
```python
async def acquire(self, timeout: Optional[float] = None) -> bool:
    async with self._lock:
        while True:
            self._refill_tokens()
            
            if self.tokens >= 1.0:
                self.tokens -= 1.0
                return True
            
            # Calculate wait time
            wait_time = tokens_needed / self.refill_rate
            
            # Wait for tokens
            await asyncio.sleep(wait_time)
```

**é—®é¢˜**:
- åœ¨é”å†… `await asyncio.sleep()` ä¼šé˜»å¡å…¶ä»–åç¨‹ï¼Œé™ä½å¹¶å‘æ€§èƒ½
- åº”è¯¥å…ˆé‡Šæ”¾é”ï¼Œç­‰å¾…åå†é‡æ–°è·å–é”

**ä¿®å¤å»ºè®®**:
```python
async def acquire(self, timeout: Optional[float] = None) -> bool:
    """Acquire a token, waiting if necessary."""
    start_time = time.monotonic()
    
    while True:
        async with self._lock:
            self._refill_tokens()
            
            if self.tokens >= 1.0:
                self.tokens -= 1.0
                self._total_requests += 1
                return True
            
            # Calculate wait time
            tokens_needed = 1.0 - self.tokens
            wait_time = tokens_needed / self.refill_rate
            
            # Check timeout
            if timeout is not None:
                elapsed = time.monotonic() - start_time
                if elapsed + wait_time > timeout:
                    logger.warning(f"Rate limit timeout after {elapsed:.2f}s")
                    return False
        
        # Release lock before sleeping
        self._total_waits += 1
        self._total_wait_time += wait_time
        logger.debug(f"Rate limit: waiting {wait_time:.3f}s for token")
        await asyncio.sleep(wait_time)
```

#### 3. burst_limit é€»è¾‘é—®é¢˜ (Line 50-52)
**ä¸¥é‡ç¨‹åº¦**: âš ï¸ Warning  
**é—®é¢˜**: `max_tokens` å’Œ `burst_limit` ä½¿ç”¨ç›¸åŒçš„å€¼ï¼Œä½†ä»¤ç‰Œæ¡¶çš„åˆå§‹ä»¤ç‰Œæ•°åº”è¯¥ç­‰äº `burst_limit`

**å½“å‰ä»£ç **:
```python
self.tokens = float(self.config.burst_limit)
self.max_tokens = float(self.config.burst_limit)
```

**é—®é¢˜**: é€»è¾‘ä¸Šæ­£ç¡®ï¼Œä½†å‘½åå¯èƒ½é€ æˆæ··æ·†ã€‚`max_tokens` åº”è¯¥æ˜ç¡®è¡¨ç¤ºæ¡¶çš„æœ€å¤§å®¹é‡ã€‚

**ä¿®å¤å»ºè®®**:
```python
# æ›´æ¸…æ™°çš„å‘½å
self.tokens = float(self.config.burst_limit)  # åˆå§‹ä»¤ç‰Œæ•°
self.max_tokens = float(self.config.burst_limit)  # æ¡¶çš„æœ€å¤§å®¹é‡
self.refill_rate = self.config.requests_per_minute / 60.0  # æ¯ç§’è¡¥å……çš„ä»¤ç‰Œæ•°
```

#### 4. åŒæ­¥è£…é¥°å™¨å®ç°ä¸å®Œæ•´ (Line 167-184)
**ä¸¥é‡ç¨‹åº¦**: âš ï¸ Warning  
**é—®é¢˜**: `rate_limited_sync` è£…é¥°å™¨åªå®ç°äº†æœ€å°é—´éš”ï¼Œæ²¡æœ‰å®ç°ä»¤ç‰Œæ¡¶é€»è¾‘

**å½“å‰ä»£ç **:
```python
def rate_limited_sync(func):
    @wraps(func)
    def wrapper(*args, **kwargs):
        limiter = get_rate_limiter()
        # For sync calls, we use a simple sleep-based approach
        min_interval = limiter.config.min_interval_ms / 1000.0
        time.sleep(min_interval)
        return func(*args, **kwargs)
    return wrapper
```

**é—®é¢˜**: 
- åªå®ç°äº†æœ€å°é—´éš”ï¼Œæ²¡æœ‰å®ç°ä»¤ç‰Œæ¡¶çš„ä»¤ç‰Œæ¶ˆè€—é€»è¾‘
- åŒæ­¥å‡½æ•°è°ƒç”¨æ—¶ï¼Œå¤šä¸ªè°ƒç”¨å¯èƒ½åŒæ—¶é€šè¿‡æ£€æŸ¥

**ä¿®å¤å»ºè®®**:
```python
def rate_limited_sync(func):
    """Decorator to rate limit sync function calls."""
    @wraps(func)
    def wrapper(*args, **kwargs):
        limiter = get_rate_limiter()
        
        # Use asyncio.run to acquire token in sync context
        # Note: This requires the event loop to not be running
        try:
            loop = asyncio.get_event_loop()
            if loop.is_running():
                # If loop is running, we can't use asyncio.run
                # Fall back to simple interval-based limiting
                min_interval = limiter.config.min_interval_ms / 1000.0
                time.sleep(min_interval)
            else:
                # Acquire token using async method
                asyncio.run(limiter.acquire())
        except RuntimeError:
            # No event loop, use simple interval
            min_interval = limiter.config.min_interval_ms / 1000.0
            time.sleep(min_interval)
        
        return func(*args, **kwargs)
    return wrapper
```

### Info é—®é¢˜

#### 5. ç»Ÿè®¡ä¿¡æ¯çº¿ç¨‹å®‰å…¨
**å»ºè®®**: `_total_requests`ã€`_total_waits` ç­‰ç»Ÿè®¡ä¿¡æ¯åœ¨å¤šçº¿ç¨‹ç¯å¢ƒä¸‹éœ€è¦åŠ é”ä¿æŠ¤

#### 6. é…ç½®éªŒè¯
**å»ºè®®**: æ·»åŠ é…ç½®å‚æ•°éªŒè¯ï¼ˆå¦‚ `requests_per_minute > 0`ï¼‰

---

## ğŸ”´ æ–‡ä»¶ 2: `manager.py`

### Critical é—®é¢˜

#### 1. Tushare è°ƒç”¨æœªä½¿ç”¨é™æµå™¨ (Line 311-319, 321-323)
**ä¸¥é‡ç¨‹åº¦**: ğŸ”´ Critical  
**é—®é¢˜**: `_fetch_daily_from_tushare` å’Œ `_fetch_minute_from_tushare` æ²¡æœ‰ä½¿ç”¨é™æµå™¨

**å½“å‰ä»£ç **:
```python
def _fetch_daily_from_tushare(self, ts_code: str, start: str, end: str) -> pd.DataFrame:
    """Fetch daily data from Tushare."""
    time.sleep(0.15)  # Simple rate limit
    try:
        df = self.tushare.pro.daily(ts_code=ts_code, start_date=start, end_date=end)
        return df if df is not None else pd.DataFrame()
    except Exception as e:
        logger.error(f"Failed to fetch daily {ts_code}: {e}")
        return pd.DataFrame()
```

**é—®é¢˜**:
- ä½¿ç”¨ `time.sleep(0.15)` è€Œä¸æ˜¯é™æµå™¨ï¼Œæ— æ³•æ§åˆ¶çªå‘è¯·æ±‚
- `_fetch_minute_from_tushare` ç›´æ¥è°ƒç”¨ `self.tushare.get_minute_data()`ï¼Œæ²¡æœ‰é™æµ

**ä¿®å¤å»ºè®®**:
```python
async def _fetch_daily_from_tushare(self, ts_code: str, start: str, end: str) -> pd.DataFrame:
    """Fetch daily data from Tushare with rate limiting."""
    # Use rate limiter
    await self.rate_limiter.acquire()
    
    try:
        df = self.tushare.pro.daily(ts_code=ts_code, start_date=start, end_date=end)
        return df if df is not None else pd.DataFrame()
    except Exception as e:
        logger.error(f"Failed to fetch daily {ts_code}: {e}")
        return pd.DataFrame()

async def _fetch_minute_from_tushare(self, ts_code: str, start: str, end: str, freq: str) -> pd.DataFrame:
    """Fetch minute data from Tushare with rate limiting."""
    # Use rate limiter
    await self.rate_limiter.acquire()
    
    return self.tushare.get_minute_data(ts_code, start, end, freq)
```

**æ³¨æ„**: è¿™éœ€è¦å°† `get_daily()` å’Œ `get_minute()` æ”¹ä¸º `async` æ–¹æ³•ã€‚

#### 2. å®æ—¶ç¼“å­˜çº¿ç¨‹å®‰å…¨é—®é¢˜ (Line 73, 158-184)
**ä¸¥é‡ç¨‹åº¦**: ğŸ”´ Critical  
**é—®é¢˜**: `_realtime_cache` å­—å…¸åœ¨å¤šçº¿ç¨‹/å¤šåç¨‹ç¯å¢ƒä¸‹æ²¡æœ‰é”ä¿æŠ¤

**å½“å‰ä»£ç **:
```python
self._realtime_cache: Dict[str, Dict[str, Any]] = {}  # symbol -> {data, timestamp}

# åœ¨ get_realtime ä¸­
for symbol in symbols:
    cached = self._realtime_cache.get(symbol)  # è¯»å–
    # ...
    self._realtime_cache[symbol] = {...}  # å†™å…¥
```

**é—®é¢˜**: 
- åœ¨å¼‚æ­¥ç¯å¢ƒä¸‹ï¼Œå¤šä¸ªåç¨‹å¯èƒ½åŒæ—¶è¯»å†™ `_realtime_cache`
- å¯èƒ½å¯¼è‡´æ•°æ®ä¸ä¸€è‡´æˆ– KeyError

**ä¿®å¤å»ºè®®**:
```python
import asyncio

class DataManager:
    def __init__(self, config: Optional[DataManagerConfig] = None):
        # ...
        self._realtime_cache: Dict[str, Dict[str, Any]] = {}
        self._cache_lock = asyncio.Lock()  # æ·»åŠ å¼‚æ­¥é”
    
    async def get_realtime(self, symbols: List[str]) -> pd.DataFrame:
        now = time.time()
        results = []
        to_fetch = []
        
        # Check cache with lock
        async with self._cache_lock:
            for symbol in symbols:
                cached = self._realtime_cache.get(symbol)
                if cached and (now - cached["timestamp"]) < self.config.realtime_cache_ttl_seconds:
                    results.append(cached["data"])
                else:
                    to_fetch.append(symbol)
        
        # Fetch uncached symbols
        if to_fetch:
            await self.rate_limiter.acquire()
            ts_codes = [self._to_ts_code(s) for s in to_fetch]
            df = self._fetch_realtime_from_tushare(ts_codes)
            
            # Update cache with lock
            async with self._cache_lock:
                for _, row in df.iterrows():
                    symbol = self._from_ts_code(row.get("ts_code", ""))
                    self._realtime_cache[symbol] = {
                        "data": row.to_dict(),
                        "timestamp": now
                    }
                    results.append(row.to_dict())
        
        return pd.DataFrame(results) if results else pd.DataFrame()
```

### Warning é—®é¢˜

#### 3. ç¼“å­˜ç­–ç•¥é—®é¢˜ (Line 95-107, 126-138)
**ä¸¥é‡ç¨‹åº¦**: âš ï¸ Warning  
**é—®é¢˜**: `get_daily()` å’Œ `get_minute()` æ˜¯åŒæ­¥æ–¹æ³•ï¼Œä½†å¯èƒ½è°ƒç”¨å¼‚æ­¥çš„ Tushare API

**é—®é¢˜**: 
- å¦‚æœ `_fetch_daily_from_tushare` æ”¹ä¸ºå¼‚æ­¥ï¼Œ`get_daily()` ä¹Ÿéœ€è¦æ”¹ä¸ºå¼‚æ­¥
- æˆ–è€…éœ€è¦åŒæ­¥ç‰ˆæœ¬çš„é™æµå™¨

**ä¿®å¤å»ºè®®**: ç»Ÿä¸€ä½¿ç”¨å¼‚æ­¥æ–¹æ³•ï¼š
```python
async def get_daily(self, symbol: str, days: int = 30) -> pd.DataFrame:
    """Get daily K-line data (async)."""
    ts_code = self._to_ts_code(symbol)
    end_date = datetime.now().strftime("%Y%m%d")
    start_date = (datetime.now() - timedelta(days=days)).strftime("%Y%m%d")
    
    # Try cache first
    cached = self.duckdb.query_daily(ts_code, start_date, end_date)
    if cached is not None and len(cached) > 0:
        logger.debug(f"Daily cache hit for {symbol}: {len(cached)} rows")
        return cached
    
    # Cache miss - fetch from Tushare
    logger.info(f"Daily cache miss for {symbol}, fetching from Tushare")
    df = await self._fetch_daily_from_tushare(ts_code, start_date, end_date)
    
    if not df.empty:
        self.duckdb.upsert_daily(df)
    
    return df
```

#### 4. æ•°æ®æ ¡éªŒé€»è¾‘ä¸å®Œæ•´ (Line 244-271)
**ä¸¥é‡ç¨‹åº¦**: âš ï¸ Warning  
**é—®é¢˜**: `validate_minute_data()` åªæ£€æŸ¥æ•°é‡ï¼Œæ²¡æœ‰æ£€æŸ¥è¿ç»­æ€§ã€ä»·æ ¼åˆç†æ€§ç­‰

**ä¿®å¤å»ºè®®**: ä½¿ç”¨å·²æœ‰çš„ `DataValidator`:
```python
from .validator import DataValidator

def validate_minute_data(self, symbol: str, date: str) -> Tuple[bool, List[Dict]]:
    """Validate minute data completeness and quality."""
    ts_code = self._to_ts_code(symbol)
    start_time = f"{date} 09:30:00"
    end_time = f"{date} 15:00:00"
    
    df = self.duckdb.query_minute(ts_code, start_time, end_time)
    if df is None or df.empty:
        return False, [{"type": "EMPTY_DATA", "message": "No data found"}]
    
    # Use DataValidator for comprehensive validation
    validator = DataValidator(strict_mode=False)
    is_valid, errors = validator.validate(df, symbol)
    
    return is_valid, errors
```

#### 5. é”™è¯¯å¤„ç†ä¸å……åˆ† (Line 311-333)
**ä¸¥é‡ç¨‹åº¦**: âš ï¸ Warning  
**é—®é¢˜**: Tushare API è°ƒç”¨å¤±è´¥æ—¶åªè®°å½•æ—¥å¿—ï¼Œæ²¡æœ‰é‡è¯•æœºåˆ¶

**ä¿®å¤å»ºè®®**: æ·»åŠ é‡è¯•é€»è¾‘ï¼š
```python
from tenacity import retry, stop_after_attempt, wait_exponential

@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=2, max=10))
async def _fetch_daily_from_tushare(self, ts_code: str, start: str, end: str) -> pd.DataFrame:
    """Fetch daily data from Tushare with retry."""
    await self.rate_limiter.acquire()
    
    try:
        df = self.tushare.pro.daily(ts_code=ts_code, start_date=start, end_date=end)
        return df if df is not None else pd.DataFrame()
    except Exception as e:
        logger.error(f"Failed to fetch daily {ts_code}: {e}")
        raise  # Re-raise for retry
```

#### 6. DuckDB æ–¹æ³•è°ƒç”¨é—®é¢˜ (Line 95, 126, 259, 278)
**ä¸¥é‡ç¨‹åº¦**: âš ï¸ Warning  
**é—®é¢˜**: è°ƒç”¨äº† `query_daily()`ã€`query_minute()`ã€`get_synced_symbols()` ç­‰æ–¹æ³•ï¼Œä½†è¿™äº›æ–¹æ³•å¯èƒ½ä¸å­˜åœ¨äº `DuckDBManager` ä¸­

**ä¿®å¤å»ºè®®**: æ£€æŸ¥ `DuckDBManager` çš„å®é™…æ–¹æ³•åï¼Œæˆ–å®ç°è¿™äº›æ–¹æ³•ã€‚

#### 7. ç¼“å­˜æ¸…ç†ç¼ºå¤±
**ä¸¥é‡ç¨‹åº¦**: âš ï¸ Warning  
**é—®é¢˜**: `_realtime_cache` æ²¡æœ‰æ¸…ç†æœºåˆ¶ï¼Œå¯èƒ½æ— é™å¢é•¿

**ä¿®å¤å»ºè®®**: æ·»åŠ å®šæœŸæ¸…ç†ï¼š
```python
async def _cleanup_cache(self):
    """Clean up expired cache entries."""
    now = time.time()
    async with self._cache_lock:
        expired = [
            symbol for symbol, data in self._realtime_cache.items()
            if (now - data["timestamp"]) > self.config.realtime_cache_ttl_seconds * 2
        ]
        for symbol in expired:
            del self._realtime_cache[symbol]
```

### Info é—®é¢˜

#### 8. ç±»å‹æ³¨è§£å¯ä»¥æ›´å®Œæ•´
**å»ºè®®**: æ·»åŠ æ›´è¯¦ç»†çš„ç±»å‹æ³¨è§£

---

## ğŸ”´ æ–‡ä»¶ 3: `quant.py`

### Critical é—®é¢˜

#### 1. å…¨å±€çŠ¶æ€çº¿ç¨‹å®‰å…¨é—®é¢˜ (Line 99-146)
**ä¸¥é‡ç¨‹åº¦**: ğŸ”´ Critical  
**é—®é¢˜**: `QuantEngineState` åœ¨å¤šçº¿ç¨‹/å¤šåç¨‹ç¯å¢ƒä¸‹æ²¡æœ‰é”ä¿æŠ¤

**å½“å‰ä»£ç **:
```python
class QuantEngineState:
    def __init__(self):
        self.running = False
        self.positions: dict = {}
        # ...

_engine_state = QuantEngineState()

def get_engine_state() -> QuantEngineState:
    return _engine_state

# åœ¨è·¯ç”±ä¸­ç›´æ¥ä¿®æ”¹
state.running = True
state.positions[symbol] = {...}
```

**é—®é¢˜**: 
- FastAPI æ˜¯å¼‚æ­¥æ¡†æ¶ï¼Œå¤šä¸ªè¯·æ±‚å¯èƒ½å¹¶å‘ä¿®æ”¹ `_engine_state`
- å¯èƒ½å¯¼è‡´æ•°æ®ç«äº‰å’Œä¸ä¸€è‡´

**ä¿®å¤å»ºè®®**:
```python
import asyncio

class QuantEngineState:
    def __init__(self):
        self._lock = asyncio.Lock()
        self.running = False
        self.positions: dict = {}
        # ...
    
    async def set_running(self, value: bool):
        async with self._lock:
            self.running = value
    
    async def get_running(self) -> bool:
        async with self._lock:
            return self.running
    
    async def add_position(self, symbol: str, position: dict):
        async with self._lock:
            self.positions[symbol] = position
    
    async def to_status(self) -> dict:
        async with self._lock:
            return {
                "engine_running": self.running,
                # ...
            }

# åœ¨è·¯ç”±ä¸­ä½¿ç”¨
@router.post("/start")
async def start_engine(request: StartEngineRequest):
    state = get_engine_state()
    
    if await state.get_running():
        return StartEngineResponse(success=False, message="Engine is already running")
    
    await state.set_running(True)
    # ...
```

#### 2. WebSocket è¿æ¥ç®¡ç†é—®é¢˜ (Line 292-333)
**ä¸¥é‡ç¨‹åº¦**: ğŸ”´ Critical  
**é—®é¢˜**: WebSocket è¿æ¥åˆ—è¡¨åœ¨å¤šåç¨‹ç¯å¢ƒä¸‹æ²¡æœ‰é”ä¿æŠ¤

**å½“å‰ä»£ç **:
```python
self.ws_connections: List[WebSocket] = []

# åœ¨ websocket_signals ä¸­
state.ws_connections.append(websocket)  # å†™å…¥
# ...
if websocket in state.ws_connections:
    state.ws_connections.remove(websocket)  # åˆ é™¤

# åœ¨ broadcast_signal ä¸­
for ws in state.ws_connections:  # è¯»å–
    await ws.send_json(message)
```

**é—®é¢˜**: 
- `broadcast_signal()` å¯èƒ½åœ¨éå†æ—¶ï¼Œ`websocket_signals()` æ­£åœ¨ä¿®æ”¹åˆ—è¡¨
- å¯èƒ½å¯¼è‡´ `RuntimeError: dictionary changed size during iteration`

**ä¿®å¤å»ºè®®**:
```python
class QuantEngineState:
    def __init__(self):
        # ...
        self.ws_connections: List[WebSocket] = []
        self._ws_lock = asyncio.Lock()
    
    async def add_ws_connection(self, ws: WebSocket):
        async with self._ws_lock:
            self.ws_connections.append(ws)
    
    async def remove_ws_connection(self, ws: WebSocket):
        async with self._ws_lock:
            if ws in self.ws_connections:
                self.ws_connections.remove(ws)
    
    async def get_ws_connections(self) -> List[WebSocket]:
        async with self._ws_lock:
            return list(self.ws_connections)  # è¿”å›å‰¯æœ¬

# åœ¨è·¯ç”±ä¸­ä½¿ç”¨
@router.websocket("/signals")
async def websocket_signals(websocket: WebSocket):
    await websocket.accept()
    state = get_engine_state()
    await state.add_ws_connection(websocket)
    
    try:
        # ...
    finally:
        await state.remove_ws_connection(websocket)

async def broadcast_signal(signal: dict):
    state = get_engine_state()
    connections = await state.get_ws_connections()  # è·å–å‰¯æœ¬
    
    message = {
        "type": "quant_signal",
        "payload": signal,
        "timestamp": datetime.now().isoformat()
    }
    
    disconnected = []
    for ws in connections:
        try:
            await ws.send_json(message)
        except Exception as e:
            logger.warning(f"Failed to send to WebSocket: {e}")
            disconnected.append(ws)
    
    # Remove disconnected clients
    for ws in disconnected:
        await state.remove_ws_connection(ws)
```

### Warning é—®é¢˜

#### 3. å‚æ•°éªŒè¯ä¸å®Œæ•´ (Line 30-34)
**ä¸¥é‡ç¨‹åº¦**: âš ï¸ Warning  
**é—®é¢˜**: `StartEngineRequest` ç¼ºå°‘å‚æ•°éªŒè¯

**ä¿®å¤å»ºè®®**:
```python
from pydantic import validator, Field
from typing import Literal

class StartEngineRequest(BaseModel):
    symbols: List[str] = Field(..., min_items=1, max_items=100)
    strategies: List[str] = Field(..., min_items=1)
    mode: Literal["simulation", "live"] = Field(default="simulation")
    
    @validator('symbols')
    def validate_symbols(cls, v):
        for symbol in v:
            if not re.match(r'^\d{6}$', symbol):
                raise ValueError(f"Invalid symbol format: {symbol}")
        return v
    
    @validator('strategies')
    def validate_strategies(cls, v):
        allowed = ["Ambush", "Ignition"]
        for strategy in v:
            if strategy not in allowed:
                raise ValueError(f"Unknown strategy: {strategy}")
        return v
```

#### 4. é”™è¯¯å¤„ç†ä¸å……åˆ† (Line 282-289)
**ä¸¥é‡ç¨‹åº¦**: âš ï¸ Warning  
**é—®é¢˜**: `sync_data()` æ•è·å¼‚å¸¸åè¿”å›é”™è¯¯å“åº”ï¼Œä½†æ²¡æœ‰è®°å½•è¯¦ç»†é”™è¯¯ä¿¡æ¯

**ä¿®å¤å»ºè®®**:
```python
@router.post("/sync", response_model=SyncResponse)
async def sync_data(request: SyncRequest = None):
    try:
        # å®é™…è°ƒç”¨ DataManager
        from ..core.quant.data.manager import DataManager
        dm = DataManager()
        result = await dm.sync_today()
        
        state = get_engine_state()
        state.last_sync_time = datetime.now().isoformat()
        state.sync_count = result["synced"]
        
        # éªŒè¯æ•°æ®
        validation = await dm.validate_today()
        state.validation_passed = validation["failed"] == 0
        
        return SyncResponse(
            success=True,
            synced=result["synced"],
            validation_passed=state.validation_passed,
            message=f"Synced {result['synced']} symbols"
        )
    except Exception as e:
        logger.error(f"Sync failed: {e}", exc_info=True)
        return SyncResponse(
            success=False,
            synced=0,
            validation_passed=False,
            message=f"Sync failed: {str(e)}"
        )
```

#### 5. WebSocket å¿ƒè·³æœºåˆ¶ (Line 314-324)
**ä¸¥é‡ç¨‹åº¦**: âš ï¸ Warning  
**é—®é¢˜**: å¿ƒè·³æœºåˆ¶å¯èƒ½ä¸å¤Ÿå¥å£®

**ä¿®å¤å»ºè®®**: æ”¹è¿›å¿ƒè·³æœºåˆ¶ï¼š
```python
@router.websocket("/signals")
async def websocket_signals(websocket: WebSocket):
    await websocket.accept()
    state = get_engine_state()
    await state.add_ws_connection(websocket)
    
    try:
        # Start heartbeat task
        heartbeat_task = asyncio.create_task(_heartbeat_loop(websocket))
        
        while True:
            try:
                data = await asyncio.wait_for(websocket.receive_text(), timeout=30)
                if data == "ping":
                    await websocket.send_text("pong")
            except asyncio.TimeoutError:
                # Heartbeat handled by task
                pass
                
    except WebSocketDisconnect:
        logger.info("WebSocket disconnected")
    except Exception as e:
        logger.error(f"WebSocket error: {e}")
    finally:
        heartbeat_task.cancel()
        await state.remove_ws_connection(websocket)

async def _heartbeat_loop(websocket: WebSocket):
    """Send periodic heartbeat."""
    try:
        while True:
            await asyncio.sleep(30)
            await websocket.send_json({
                "type": "heartbeat",
                "timestamp": datetime.now().isoformat()
            })
    except asyncio.CancelledError:
        pass
```

#### 6. ç¼ºå°‘ DataManager é›†æˆ
**ä¸¥é‡ç¨‹åº¦**: âš ï¸ Warning  
**é—®é¢˜**: `sync_data()` å’Œ `validate_today()` æ²¡æœ‰å®é™…è°ƒç”¨ `DataManager`

**ä¿®å¤å»ºè®®**: é›†æˆ `DataManager`ï¼ˆè§ä¸Šé¢çš„ä»£ç ç¤ºä¾‹ï¼‰

### Info é—®é¢˜

#### 7. ç¼ºå°‘å¼•æ“å®é™…å¯åŠ¨é€»è¾‘
**å»ºè®®**: `start_engine()` åº”è¯¥å®é™…å¯åŠ¨ `RealtimeEngine`

#### 8. ç¼ºå°‘è®¤è¯æˆæƒ
**å»ºè®®**: å®ç›˜æ¥å£éœ€è¦æ·»åŠ è®¤è¯ä¸­é—´ä»¶

---

## âœ… æ–‡ä»¶ 4: `app.py`

### å®¡æŸ¥æ„è§

**çŠ¶æ€**: âœ… **PASS**

**éªŒè¯ç‚¹**:
- âœ… Line 79-83: æ­£ç¡®å¯¼å…¥å’Œæ³¨å†Œ `quant` router
- âœ… ä½¿ç”¨ try-except å¤„ç†å¯é€‰æ¨¡å—ï¼Œç¬¦åˆç°æœ‰æ¨¡å¼
- âœ… ä»£ç é£æ ¼ä¸€è‡´

**ç»“è®º**: `app.py` çš„ä¿®æ”¹æ­£ç¡®ï¼Œæ— éœ€ä¿®æ”¹ã€‚

---

## ğŸ“Š æ€»ä½“å»ºè®®

### 1. ç«‹å³ä¿®å¤ (P0)
1. ğŸ”´ ä¿®å¤å•ä¾‹æ¨¡å¼çš„çº¿ç¨‹å®‰å…¨é—®é¢˜
2. ğŸ”´ ä¿®å¤ Tushare è°ƒç”¨æœªä½¿ç”¨é™æµå™¨çš„é—®é¢˜
3. ğŸ”´ ä¿®å¤å®æ—¶ç¼“å­˜çš„çº¿ç¨‹å®‰å…¨é—®é¢˜
4. ğŸ”´ ä¿®å¤å…¨å±€çŠ¶æ€çš„çº¿ç¨‹å®‰å…¨é—®é¢˜
5. ğŸ”´ ä¿®å¤ WebSocket è¿æ¥ç®¡ç†çš„çº¿ç¨‹å®‰å…¨é—®é¢˜

### 2. å°½å¿«ä¿®å¤ (P1)
1. âš ï¸ æ”¹è¿›ä»¤ç‰Œæ¡¶ç®—æ³•çš„é”ä½¿ç”¨
2. âš ï¸ ç»Ÿä¸€ä½¿ç”¨å¼‚æ­¥æ–¹æ³•
3. âš ï¸ æ·»åŠ å‚æ•°éªŒè¯
4. âš ï¸ å®Œå–„é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶
5. âš ï¸ é›†æˆ DataManager åˆ° API è·¯ç”±

### 3. è®¡åˆ’ä¼˜åŒ– (P2)
1. â„¹ï¸ æ·»åŠ ç¼“å­˜æ¸…ç†æœºåˆ¶
2. â„¹ï¸ æ”¹è¿› WebSocket å¿ƒè·³æœºåˆ¶
3. â„¹ï¸ æ·»åŠ è®¤è¯æˆæƒ
4. â„¹ï¸ æ·»åŠ å•å…ƒæµ‹è¯•

---

## âœ… ç¬¦åˆé¡¹ï¼ˆä¼˜ç‚¹ï¼‰

1. **ä»£ç ç»“æ„æ¸…æ™°**: æ¨¡å—èŒè´£åˆ’åˆ†æ˜ç¡®
2. **ç±»å‹æ³¨è§£å®Œæ•´**: ä½¿ç”¨äº† Pydantic æ¨¡å‹
3. **æ—¥å¿—è®°å½•å®Œå–„**: å…³é”®æ“ä½œéƒ½æœ‰æ—¥å¿—
4. **é…ç½®åŒ–è®¾è®¡**: ä½¿ç”¨ dataclass é…ç½®

---

## ğŸ¯ ä¿®å¤ä¼˜å…ˆçº§å»ºè®®

### ç«‹å³ä¿®å¤ (P0)
1. ğŸ”´ å•ä¾‹æ¨¡å¼çº¿ç¨‹å®‰å…¨
2. ğŸ”´ Tushare é™æµå™¨é›†æˆ
3. ğŸ”´ å®æ—¶ç¼“å­˜çº¿ç¨‹å®‰å…¨
4. ğŸ”´ å…¨å±€çŠ¶æ€çº¿ç¨‹å®‰å…¨
5. ğŸ”´ WebSocket è¿æ¥ç®¡ç†çº¿ç¨‹å®‰å…¨

### å°½å¿«ä¿®å¤ (P1)
1. âš ï¸ ä»¤ç‰Œæ¡¶ç®—æ³•é”ä¼˜åŒ–
2. âš ï¸ å¼‚æ­¥æ–¹æ³•ç»Ÿä¸€
3. âš ï¸ å‚æ•°éªŒè¯
4. âš ï¸ é”™è¯¯å¤„ç†å®Œå–„

### è®¡åˆ’ä¼˜åŒ– (P2)
1. â„¹ï¸ ç¼“å­˜æ¸…ç†
2. â„¹ï¸ å¿ƒè·³æœºåˆ¶
3. â„¹ï¸ è®¤è¯æˆæƒ
4. â„¹ï¸ å•å…ƒæµ‹è¯•

---

## ğŸ“ æ€»ç»“

æ•´ä½“ä»£ç è´¨é‡**è‰¯å¥½**ï¼Œä½†å­˜åœ¨ä¸€äº›**å…³é”®çš„çº¿ç¨‹/å¼‚æ­¥å®‰å…¨é—®é¢˜**éœ€è¦ç«‹å³ä¿®å¤ã€‚ä¸»è¦é—®é¢˜é›†ä¸­åœ¨ï¼š

1. **çº¿ç¨‹å®‰å…¨**: å…¨å±€çŠ¶æ€ã€ç¼“å­˜ã€WebSocket è¿æ¥åˆ—è¡¨éƒ½éœ€è¦é”ä¿æŠ¤
2. **é™æµå™¨é›†æˆ**: Tushare è°ƒç”¨éœ€è¦æ­£ç¡®ä½¿ç”¨é™æµå™¨
3. **å¼‚æ­¥ä¸€è‡´æ€§**: éœ€è¦ç»Ÿä¸€ä½¿ç”¨å¼‚æ­¥æ–¹æ³•

å»ºè®®æŒ‰ç…§ä¼˜å…ˆçº§é€æ­¥ä¿®å¤ï¼Œå¹¶åœ¨ä¿®å¤åæ·»åŠ ç›¸åº”çš„å•å…ƒæµ‹è¯•ã€‚

---

**å®¡æŸ¥å®Œæˆæ—¶é—´**: 2025-01-XX  
**ä¸‹æ¬¡å®¡æŸ¥å»ºè®®**: ä¿®å¤ Critical é—®é¢˜åè¿›è¡Œå›å½’å®¡æŸ¥

