# ADR 0001: 数据管道与消息系统选择

**状态**: 提议中  
**作者**: 项目组  
**日期**: 2024-03-08

## 背景
- 重构目标是构建分时数据处理中心，需要可靠的实时数据分发链路。
- 现有系统主要依赖内存缓存与直接 API 调用，缺少统一的数据流与重放能力。
- 需要支持秒级的行情吞吐、容错及后续扩容。

## 决策
- **短期 (P0-P1)**：采用 `Redis Stream` 作为流式缓冲层，快速落地采集→清洗→特征流水线。
- **中期 (P2+)**：预留切换至 `Kafka` 的能力，用于支撑更高吞吐与多消费者场景。
- 所有服务通过统一的 Topic 命名规范与消费者组管理，支持回放与重试。

## 方案详情
- `collector-gateway` 将原始 Tick 写入 `STREAM dfp:raw_ticks`。
- `data-cleaner` 消费 raw stream，输出到 `dfp:clean_ticks` 与实时缓存。
- `feature-pipeline`、`strategy-engine` 等模块基于 `clean_ticks` 及衍生 Topic 工作。
- 定义统一的消息字段：源、代码、时间戳、行情数据、原始字段快照。
- 提供监控指标：滞后、堆积量、消费者延迟。

## 权衡
- **Redis Stream 优点**：部署简单、与现有基础设施兼容、开发效率高、支持阻塞读取和消费组。
- **Redis Stream 缺点**：持久性与水平扩展能力有限，适用于快速验证阶段。
- **Kafka 优点**：高吞吐、分区扩展、生态成熟，适合长线演进。
- **Kafka 缺点**：部署维护成本高、初期开发曲线陡峭。
- 结论：先 Redis Stream，待 P0-P1 稳定后评估 Kafka 迁移节奏。

## 影响
- 需要运维准备 Redis 持久化策略及监控，防止内存挤压。
- 开发团队需要编写统一的 Stream 接入 SDK。
- 监控团队需加入流量、延迟、堆积告警规则。

## 后续步骤
- [ ] 与运维确认 Redis 集群配置、持久化策略、备份方案。
- [ ] 在 `collector-gateway` 与 `data-cleaner` 中实现 Stream 接入封装。
- [ ] 完成 Topic 命名规范与消息 Schema 文档。
- [ ] 在 P1 阶段之前评估 Kafka 的 PoC 与迁移成本。
