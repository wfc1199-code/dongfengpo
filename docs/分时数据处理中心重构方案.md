## 分时数据处理中心重构方案

### 1. 愿景与目标
- **定位**：构建统一的分时数据处理中心，实时聚合多源行情，输出高置信度的可交易机会。
- **目标**：实现准实时的机会识别、持续跟踪与风险提示，为短线交易策略提供数据与信号支撑。
- **关键指标**：数据延迟 < 2s、机会信号准确率提升 20%+、核心服务可用性 ≥ 99.5%、策略回测覆盖率 ≥ 90%。

### 2. 顶层架构
```
┌──────────────────────────────────────────────────────────┐
│                       体验层 Experience                  │
│  实时驾驶舱  策略评估台  机会列表 API/WebSocket  通知中心  │
├──────────────────────────────────────────────────────────┤
│                       服务层 Services                   │
│  Signal Service  Opportunity Manager  Backtest Service   │
│  Analytics API   Report Service      Risk Guard          │
├──────────────────────────────────────────────────────────┤
│                       分析层 Analytics                  │
│  Feature Pipeline  Opportunity Engine  Strategy Sandbox  │
│  Scoring & Ranking  Alert Orchestrator                  │
├──────────────────────────────────────────────────────────┤
│                       数据层 Data                       │
│  Data Ingestor  Stream Buffer  Preprocessor  Data Lake   │
│  Metadata Store  Quality Monitor                        │
└──────────────────────────────────────────────────────────┘
```

### 3. 核心模块说明
1. **Data Ingestor**：
   - 接入东方财富、腾讯、Tushare 及备用数据源，支持 HTTP/WebSocket 双通道。
   - 统一速率控制、断线重连、冗余拉链式补数。
2. **Stream Buffer**：
   - 采用 Redis Stream / Kafka 管理分时流，提供持久化与回放能力。
   - 通过 Topic 切分（个股、板块、资金、指标）提升消费效率。
3. **Preprocessor & Feature Pipeline**：
   - 时间对齐、异常修正、补齐缺失；生成量价波动、盘口深度、资金流等特征。
   - 输出标准化 `FeatureSnapshot` 供策略消费。
4. **Opportunity Engine**：
   - 策略插件化：拉升、板块轮动、资金异常、涨停/二板、风险控制等检测器。
   - 支持规则、机器学习、统计模型多种实现形式。
5. **Signal Service & Opportunity Manager**：
   - 统一管理机会生命周期（发现→确认→跟踪→结束）。
   - 输出结构化信号（置信度、目标区间、持有建议、风险提示）。
6. **Backtest & Analytics**：
   - 基于历史分时回放的策略评估，提供收益、回撤、命中率等指标。
   - 支持参数扫描、对比分析、A/B 测试。
7. **Experience Layer**：
   - 新版驾驶舱：实时机会列表、信号热力、策略对比、风险面板。
   - API/WebSocket：开放式接口供其他系统订阅。

### 4. 阶段性里程碑
| 阶段 | 目标 | 关键交付物 |
| --- | --- | --- |
| P0 数据骨架 | 建立多源采集、流式缓冲、数据清洗框架 | Data Ingestor、Stream Buffer PoC、数据质量仪表盘 |
| P1 机会引擎 MVP | 选定 2-3 个高价值策略打通端到端流程 | Feature Pipeline MVP、Opportunity Engine 基础版、信号 API |
| P2 回测与评估 | 完善历史数据存储与策略评估工具 | Backtest Service、策略报表、指标可视化 |
| P3 前端重构 | 重构驾驶舱并整合策略控制台 | 新版 UI、实时订阅中心、通知管理 |
| P4 扩展与演进 | 接入更多策略、强化风控与智能调度 | 策略商店、模型热更新、风险警戒体系 |

### 5. 任务分解（首两阶段）
**P0 数据骨架**
- 数据源适配器重写：抽象接口 `DataSourceAdapter`，实现东方财富/腾讯/Tushare。
- 构建 `Data Collector` 服务，推送到 Redis Stream/Kafka。
- 开发 `Data Cleaner`，处理缺失、异常、对齐，写入 `Realtime Store`（Redis）与 `Data Lake`（Parquet/ClickHouse）。
- 数据质量监控：延迟、缺失率、异常值统计，Prometheus 仪表盘。

**P1 机会引擎 MVP**
- 设计 `FeatureSnapshot`/`SignalPayload` 数据契约（Pydantic Schema）。
- 实现策略框架：统一生命周期、配置、评分接口。
- 首批策略：
  1. **拉升异动**（涨速+量价背离+盘口强度）。
  2. **板块轮动**（行业热度突增+龙头突破）。
  3. **资金异常**（主动买卖盘差值+大单密度）。
- 机会管理服务：聚合多策略信号，去重合并，输出给前端/下游。
- 初版 WebSocket 信号推送与 REST 查询 API。

### 6. 技术选型建议
- **语言与框架**：后端 Python (FastAPI + asyncio)；实时处理可评估 Faust/BytesIO 或 Rust/Golang 模块化组件。
- **消息与缓存**：Redis Stream（快速实现）→ 可升级 Kafka；Redis Cluster 做热点缓存。
- **数据存储**：
  - 实时：Redis Sorted Set / Timeseries。
  - 历史：ClickHouse / Parquet on S3。
- **调度与任务**：Celery/Arq 处理批量任务，Prefect/Airflow 管理批处理流程。
- **监控**：Prometheus + Grafana + Loki，统一日志与指标。
- **前端**：React + Zustand/Redux Toolkit，ECharts 封装，支持模块化布局。

### 7. 风险与应对
- **数据不稳定**：提供多源兜底、心跳监测、历史补数脚本。
- **策略有效性**：引入离线回测、实时模拟盘，提供策略指标仪表盘。
- **性能瓶颈**：预留水平扩展方案（Kafka 分片、计算节点扩容、缓存层）。
- **团队协同**：建立编码规范、评审模板、文档中心，确保跨模块协作顺畅。

### 8. 下一步行动
1. 召开 Kickoff，对齐范围与不做的事项，确认人力与里程碑。
2. 编写关键 ADR：数据管道选型、消息系统、策略框架接口、数据契约。
3. 建立基础仓库结构：`services/collector`, `services/engine`, `services/signal`, `webapp` 等，保留向后兼容层。
4. 启动 P0 研发：完成数据源适配器与流式采集 PoC，搭建监控。

---
本方案作为初版蓝图，后续会根据实际调研与技术验证结果不断迭代。
