#!/usr/bin/env python3
"""
DuckDB æ•°æ®æ¹–åˆå§‹åŒ–è„šæœ¬

ç”¨é€”:
- åˆ›å»º quant_data ç›®å½•ç»“æ„
- åˆå§‹åŒ– DuckDB æ•°æ®åº“
- åˆ›å»ºå¿…è¦çš„è¡¨å’Œç´¢å¼•
- æµ‹è¯•åŸºæœ¬è¯»å†™åŠŸèƒ½

ç”¨æ³•:
    python scripts/init_duckdb.py
"""

import os
import sys
from pathlib import Path
from datetime import datetime

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))


def init_data_lake(data_root: str = "./quant_data"):
    """åˆå§‹åŒ–æ•°æ®æ¹–ç›®å½•ç»“æ„"""
    print("=" * 60)
    print("DuckDB æ•°æ®æ¹–åˆå§‹åŒ–")
    print("=" * 60)
    
    root = Path(data_root)
    
    # åˆ›å»ºç›®å½•ç»“æ„
    directories = [
        root / "market_data",      # åˆ†é’Ÿçº¿ Parquet æ–‡ä»¶
        root / "daily_data",       # æ—¥çº¿ Parquet æ–‡ä»¶
        root / "backup",           # å®šæœŸå¤‡ä»½
        root / "checkpoints",      # æ–­ç‚¹ç»­ä¼ æ£€æŸ¥ç‚¹
        root / "logs",             # åŒæ­¥æ—¥å¿—
    ]
    
    for dir_path in directories:
        dir_path.mkdir(parents=True, exist_ok=True)
        print(f"  âœ… åˆ›å»ºç›®å½•: {dir_path}")
    
    # åˆå§‹åŒ– DuckDB
    print("\nğŸ“¦ åˆå§‹åŒ– DuckDB...")
    try:
        from signal_api.core.quant.data.duckdb_manager import DuckDBManager
        
        dm = DuckDBManager(data_root=str(root))
        
        # æµ‹è¯•è¿æ¥
        conn = dm.conn
        result = conn.execute("SELECT 1 as test").fetchone()
        print(f"  âœ… DuckDB è¿æ¥æ­£å¸¸: {result}")
        
        dm.close()
        
    except Exception as e:
        print(f"  âš ï¸ DuckDB åˆå§‹åŒ–å¤±è´¥: {e}")
        return False
    
    # åˆ›å»ºå…ƒæ•°æ®æ–‡ä»¶
    meta_file = root / "metadata.json"
    if not meta_file.exists():
        import json
        metadata = {
            "created_at": datetime.now().isoformat(),
            "version": "1.0",
            "description": "AI Quant Platform Data Lake",
            "directories": {
                "market_data": "åˆ†é’Ÿçº¿ Parquet æ–‡ä»¶",
                "daily_data": "æ—¥çº¿ Parquet æ–‡ä»¶",
                "backup": "å®šæœŸå¤‡ä»½",
                "checkpoints": "æ–­ç‚¹ç»­ä¼ æ£€æŸ¥ç‚¹",
                "logs": "åŒæ­¥æ—¥å¿—",
            }
        }
        with open(meta_file, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)
        print(f"  âœ… åˆ›å»ºå…ƒæ•°æ®æ–‡ä»¶: {meta_file}")
    
    print("\n" + "=" * 60)
    print("âœ… æ•°æ®æ¹–åˆå§‹åŒ–å®Œæˆ!")
    print("=" * 60)
    print(f"\næ•°æ®ç›®å½•: {root.absolute()}")
    print("\nä¸‹ä¸€æ­¥:")
    print("  1. é…ç½® TUSHARE_TOKEN ç¯å¢ƒå˜é‡")
    print("  2. è¿è¡Œ sync_task.py åŒæ­¥å†å²æ•°æ®")
    print("  3. è®¾ç½®å®šæ—¶ä»»åŠ¡æ¯æ—¥åŒæ­¥")
    
    return True


def test_data_flow():
    """æµ‹è¯•æ•°æ®æµ"""
    print("\nğŸ“Š æµ‹è¯•æ•°æ®æµ...")
    
    try:
        from signal_api.core.quant.data.manager import DataManager, DataManagerConfig
        
        token = os.environ.get('TUSHARE_TOKEN')
        if not token:
            print("  âš ï¸ TUSHARE_TOKEN æœªé…ç½®ï¼Œè·³è¿‡æ•°æ®æµæµ‹è¯•")
            return True
        
        config = DataManagerConfig(tushare_token=token)
        dm = DataManager(config)
        
        # æµ‹è¯•åˆ†é’Ÿçº¿
        print("  æµ‹è¯•åˆ†é’Ÿçº¿è·å– (000001)...")
        minute_df = dm.get_minute('000001', days=1, freq='1min')
        if minute_df is not None and len(minute_df) > 0:
            print(f"    âœ… è·å– {len(minute_df)} æ¡åˆ†é’Ÿçº¿")
        else:
            print(f"    âš ï¸ æ— åˆ†é’Ÿçº¿æ•°æ®")
        
        # æµ‹è¯•æ—¥çº¿
        print("  æµ‹è¯•æ—¥çº¿è·å– (000001)...")
        daily_df = dm.get_daily('000001', days=30)
        if daily_df is not None and len(daily_df) > 0:
            print(f"    âœ… è·å– {len(daily_df)} æ¡æ—¥çº¿")
        else:
            print(f"    âš ï¸ æ— æ—¥çº¿æ•°æ®")
        
        return True
        
    except Exception as e:
        print(f"  âš ï¸ æ•°æ®æµæµ‹è¯•å¤±è´¥: {e}")
        return False


if __name__ == "__main__":
    # åˆ‡æ¢åˆ°é¡¹ç›®æ ¹ç›®å½•
    os.chdir(project_root)
    
    # åˆå§‹åŒ–æ•°æ®æ¹–
    success = init_data_lake("./quant_data")
    
    if success:
        # æµ‹è¯•æ•°æ®æµ
        test_data_flow()
