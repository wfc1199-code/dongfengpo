"""
æ¶¨åœæ¿ / è¿æ¿è¿½è¸ª API
ä½¿ç”¨ AkShare stock_zt_pool_em API è·å–å‡†ç¡®çš„è¿æ¿æ•°æ®
é›†æˆç»Ÿä¸€5ç»´è¯„åˆ†ç³»ç»Ÿ
"""
from fastapi import APIRouter
import asyncio
import logging
from typing import Dict, Any
from datetime import datetime, timedelta

# å¯¼å…¥ç»Ÿä¸€è¯„åˆ†å™¨
from ..core.quant.scorer import get_scorer, StockMetrics

router = APIRouter(
    prefix="/api/limit-up",
    tags=["limit-up"],
    responses={404: {"description": "Not found"}},
)

logger = logging.getLogger(__name__)


@router.get("/predictions")
async def get_limit_up_predictions(limit: int = 50):
    """
    è·å–æ¶¨åœæ± æ•°æ®ï¼ˆåŒ…å«å‡†ç¡®çš„è¿æ¿æ•°ï¼‰
    
    ä½¿ç”¨ AkShare çš„ stock_zt_pool_em APIï¼Œä¸åŸå§‹åç«¯ä¸€è‡´
    è¿”å›åŒ…å« consecutive_days çš„è‚¡ç¥¨åˆ—è¡¨
    """
    try:
        import akshare as ak
        
        logger.info("ğŸ” è·å–æ¶¨åœæ± æ•°æ®ï¼ˆAkShare APIï¼‰...")
        
        loop = asyncio.get_event_loop()
        df = None
        data_date = None
        
        # å°è¯•è·å–æ¶¨åœæ•°æ®ï¼šå…ˆå°è¯•ä»Šå¤©ï¼Œå¦‚æœä¸ºç©ºåˆ™å°è¯•å‰å‡ ä¸ªäº¤æ˜“æ—¥
        for days_ago in range(5):
            try_date = datetime.now() - timedelta(days=days_ago)
            date_str = try_date.strftime("%Y%m%d")
            
            # è·³è¿‡å‘¨æœ«
            if try_date.weekday() >= 5:
                continue
            
            try:
                df = await loop.run_in_executor(
                    None,
                    ak.stock_zt_pool_em,
                    date_str
                )
                
                if df is not None and not df.empty:
                    data_date = date_str
                    if days_ago == 0:
                        logger.info(f"âœ… è·å–åˆ° {len(df)} åªæ¶¨åœè‚¡ç¥¨ - ä»Šæ—¥æ•°æ®")
                    else:
                        logger.info(f"âœ… è·å–åˆ° {len(df)} åªæ¶¨åœè‚¡ç¥¨ - {date_str}æ•°æ®")
                    break
                else:
                    logger.debug(f"{date_str} æ— æ¶¨åœæ•°æ®ï¼Œå°è¯•å‰ä¸€å¤©")
                    
            except Exception as e:
                logger.debug(f"è·å– {date_str} æ¶¨åœæ•°æ®å¤±è´¥: {e}")
                continue
        
        if df is None or df.empty:
            logger.warning("æ¶¨åœæ± æ•°æ®ä¸ºç©ºï¼ˆåŒ…æ‹¬å†å²æ•°æ®ï¼‰ï¼Œè¿”å›ç©ºåˆ—è¡¨")
            return {
                "code": 200,
                "message": "æš‚æ— æ¶¨åœæ•°æ®",
                "data": {"stocks": []},
                "date": None
            }
        
        # è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
        stocks = []
        for _, row in df.head(limit * 2).iterrows():  # å–æ›´å¤šä»¥ä¾¿æ’åºåç­›é€‰
            try:
                code = str(row.get('ä»£ç ', ''))
                name = str(row.get('åç§°', ''))
                price = float(row.get('æœ€æ–°ä»·', 0) or 0)
                change_percent = float(row.get('æ¶¨è·Œå¹…', 0) or 0)
                volume = int(row.get('æˆäº¤é‡', 0) or 0)
                amount = float(row.get('æˆäº¤é¢', 0) or 0)
                turnover_rate = float(row.get('æ¢æ‰‹ç‡', 0) or 0)
                consecutive_days = int(row.get('è¿æ¿æ•°', 1) or 1)  # AkShare ç›´æ¥è¿”å›è¿æ¿æ•°
                industry = str(row.get('æ‰€å±è¡Œä¸š', 'å…¶ä»–') or 'å…¶ä»–')
                
                # å°æ¿æ—¶é—´
                first_limit_time = str(row.get('é¦–æ¬¡å°æ¿æ—¶é—´', '') or '')
                last_limit_time = str(row.get('æœ€åå°æ¿æ—¶é—´', '') or '')
                
                stocks.append({
                    "symbol": code,
                    "code": code,  # å…¼å®¹å‰ç«¯
                    "name": name,
                    "price": price,
                    "change_percent": change_percent,
                    "consecutive_days": consecutive_days,
                    "industry": industry,
                    "volume": volume,
                    "amount": amount,
                    "turnover_rate": turnover_rate,
                    "first_limit_up_time": first_limit_time,
                    "last_limit_up_time": last_limit_time,
                    "reason": f"{consecutive_days}è¿æ¿" if consecutive_days > 1 else "é¦–æ¿æ¶¨åœ",
                    "data_source": "akshare_limit_up_pool"
                })
            except Exception as e:
                logger.warning(f"è½¬æ¢æ¶¨åœè‚¡ç¥¨æ•°æ®å¤±è´¥: {e}")
                continue
        
        # æŒ‰è¿æ¿æ•°æ’åºï¼ˆé«˜åˆ°ä½ï¼‰
        stocks.sort(key=lambda x: x['consecutive_days'], reverse=True)
        stocks = stocks[:limit]
        
        logger.info(f"âœ… è¿”å› {len(stocks)} åªæ¶¨åœè‚¡ç¥¨ï¼ˆåŒ…å«å‡†ç¡®è¿æ¿æ•°ï¼‰")
        
        # ç»Ÿè®¡è¿æ¿åˆ†å¸ƒ
        board_stats = {}
        for s in stocks:
            days = s['consecutive_days']
            board_stats[days] = board_stats.get(days, 0) + 1
        logger.info(f"ğŸ“Š è¿æ¿åˆ†å¸ƒ: {board_stats}")
        
        return {
            "code": 200,
            "message": "success",
            "data": {"stocks": stocks},
            "date": data_date
        }
        
    except ImportError:
        logger.error("akshare æœªå®‰è£…ï¼Œä½¿ç”¨å›é€€æ–¹æ¡ˆ")
        return await get_fallback_limit_up(limit)
    except Exception as e:
        logger.error(f"è·å–æ¶¨åœæ± æ•°æ®å¤±è´¥: {e}")
        return await get_fallback_limit_up(limit)


async def get_fallback_limit_up(limit: int) -> Dict[str, Any]:
    """
    å›é€€æ–¹æ¡ˆï¼šä½¿ç”¨ä¸œæ–¹è´¢å¯Œç®€å•æ¥å£è·å–æ¶¨åœè‚¡ç¥¨
    æ³¨æ„ï¼šæ­¤æ–¹æ³•æ— æ³•è·å–å‡†ç¡®çš„è¿æ¿æ•°
    """
    import aiohttp
    
    logger.warning("âš ï¸ ä½¿ç”¨å›é€€æ–¹æ¡ˆè·å–æ¶¨åœæ•°æ®ï¼ˆæ— è¿æ¿æ•°ï¼‰")
    
    url = 'http://push2.eastmoney.com/api/qt/clist/get'
    params = {
        'pn': '1', 'pz': '100', 'po': '1', 'np': '1',
        'ut': 'bd1d9ddb04089700cf9c27f6f7426281',
        'fltt': '2', 'invt': '2', 'fid': 'f3',
        'fs': 'm:0+t:6,m:0+t:13,m:0+t:80,m:1+t:2,m:1+t:23',
        'fields': 'f1,f2,f3,f4,f5,f6,f12,f14'
    }
    
    timeout = aiohttp.ClientTimeout(total=5)
    try:
        async with aiohttp.ClientSession(timeout=timeout) as session:
            async with session.get(url, params=params) as response:
                stocks = []
                if response.status == 200:
                    data = await response.json()
                    if 'data' in data and 'diff' in data['data']:
                        for s in data['data']['diff']:
                            change_pct = float(s.get('f3', 0) or 0)
                            if change_pct > 9.0:  # æ¶¨å¹…å¤§äº9%è§†ä¸ºæ¶¨åœ
                                stocks.append({
                                    "symbol": s.get('f12'),
                                    "code": s.get('f12'),
                                    "name": s.get('f14'),
                                    "price": s.get('f2'),
                                    "change_percent": change_pct,
                                    "consecutive_days": 1,  # å›é€€æ–¹æ¡ˆæ— æ³•è·å–çœŸå®è¿æ¿æ•°
                                    "reason": "æ¶¨åœï¼ˆè¿æ¿æ•°æœªçŸ¥ï¼‰",
                                    "data_source": "eastmoney_fallback"
                                })
                return {
                    "code": 200, 
                    "message": "success (fallback)", 
                    "data": {"stocks": stocks[:limit]},
                    "date": None
                }
    except Exception as e:
        logger.error(f"å›é€€æ–¹æ¡ˆä¹Ÿå¤±è´¥: {e}")
        return {"code": 200, "message": "error", "data": {"stocks": []}}


# =============================================================================
# å†…éƒ¨å¸®åŠ©å‡½æ•°ï¼šè·å–æ¶¨åœæ± DataFrameï¼ˆå¸¦ç¼“å­˜ï¼‰
# =============================================================================
_zt_pool_cache = {"df": None, "date": None, "timestamp": None}

async def _get_zt_pool_df():
    """è·å–æ¶¨åœæ± DataFrameï¼ˆå¸¦å†…å­˜ç¼“å­˜ï¼‰"""
    import akshare as ak
    
    # ç®€å•çš„å†…å­˜ç¼“å­˜ï¼ˆ60ç§’æœ‰æ•ˆï¼‰
    now = datetime.now()
    if (_zt_pool_cache["df"] is not None and 
        _zt_pool_cache["timestamp"] and 
        (now - _zt_pool_cache["timestamp"]).seconds < 60):
        return _zt_pool_cache["df"], _zt_pool_cache["date"]
    
    loop = asyncio.get_event_loop()
    
    for days_ago in range(5):
        try_date = now - timedelta(days=days_ago)
        if try_date.weekday() >= 5:
            continue
        
        date_str = try_date.strftime("%Y%m%d")
        try:
            df = await loop.run_in_executor(None, ak.stock_zt_pool_em, date_str)
            if df is not None and not df.empty:
                _zt_pool_cache["df"] = df
                _zt_pool_cache["date"] = date_str
                _zt_pool_cache["timestamp"] = now
                logger.info(f"âœ… ç¼“å­˜æ¶¨åœæ± æ•°æ®: {len(df)}åª, æ—¥æœŸ: {date_str}")
                return df, date_str
        except Exception as e:
            logger.debug(f"è·å– {date_str} æ¶¨åœæ•°æ®å¤±è´¥: {e}")
            continue
    
    return None, None


# =============================================================================
# äºŒæ¿å€™é€‰æ¥å£
# =============================================================================
@router.get("/second-board-candidates")
async def get_second_board_candidates(limit: int = 20):
    """
    è·å–äºŒæ¿å€™é€‰è‚¡ç¥¨
    
    ä»é¦–æ¿è‚¡ç¥¨ä¸­ç­›é€‰æ˜æ—¥å¯èƒ½æ¶¨åœçš„å€™é€‰ï¼š
    - ç­›é€‰è¿æ¿æ•°=1çš„é¦–æ¿è‚¡ç¥¨
    - æ’é™¤ä¸€å­—æ¿
    - æ’é™¤å¼±åŠ¿è‚¡ï¼ˆç‚¸æ¿è¿‡å¤šã€æ¢æ‰‹ç‡ä½ã€æˆäº¤é¢ä½ï¼‰
    - è®¡ç®—æ™‹çº§æ¦‚ç‡
    """
    try:
        df, data_date = await _get_zt_pool_df()
        
        if df is None or df.empty:
            return {
                "code": 200,
                "message": "æš‚æ— æ¶¨åœæ•°æ®",
                "data": {"candidates": [], "total_count": 0, "update_time": datetime.now().isoformat()}
            }
        
        # ç­›é€‰é¦–æ¿è‚¡ç¥¨ï¼ˆè¿æ¿æ•° == 1ï¼‰
        if 'è¿æ¿æ•°' in df.columns:
            first_board_df = df[df['è¿æ¿æ•°'] == 1].copy()
            logger.info(f"âœ… ç­›é€‰å‡º {len(first_board_df)} åªé¦–æ¿è‚¡ç¥¨ï¼ˆå…± {len(df)} åªæ¶¨åœï¼‰")
        else:
            first_board_df = df.head(30).copy()
            logger.warning("âš ï¸ æ•°æ®ä¸­æ²¡æœ‰'è¿æ¿æ•°'å­—æ®µï¼Œè¿”å›å‰30åª")
        
        # æ’é™¤ä¸€å­—æ¿
        if 'ç‚¸æ¿æ¬¡æ•°' in first_board_df.columns and 'é¦–æ¬¡å°æ¿æ—¶é—´' in first_board_df.columns:
            before_filter = len(first_board_df)
            
            def is_yi_zi_ban(row):
                seal_time = str(row.get('é¦–æ¬¡å°æ¿æ—¶é—´', ''))
                burst_count = int(row.get('ç‚¸æ¿æ¬¡æ•°', 0) or 0)
                if seal_time and len(seal_time) >= 4:
                    if seal_time[:4] <= '0925' and burst_count == 0:
                        return True
                return False
            
            first_board_df = first_board_df[~first_board_df.apply(is_yi_zi_ban, axis=1)]
            logger.info(f"âœ… æ’é™¤ä¸€å­—æ¿åå‰©ä½™ {len(first_board_df)} åªï¼ˆè¿‡æ»¤ {before_filter - len(first_board_df)} åªï¼‰")
        
        candidates = []
        
        for _, row in first_board_df.iterrows():
            code = str(row.get('ä»£ç ', ''))
            name = str(row.get('åç§°', ''))
            change_percent = float(row.get('æ¶¨è·Œå¹…', 0) or 0)
            current_price = float(row.get('æœ€æ–°ä»·', 0) or 0)
            turnover_rate = float(row.get('æ¢æ‰‹ç‡', 0) or 0)
            amount = float(row.get('æˆäº¤é¢', 0) or 0)
            seal_time = str(row.get('é¦–æ¬¡å°æ¿æ—¶é—´', '09:30') or '09:30')
            burst_count = int(row.get('ç‚¸æ¿æ¬¡æ•°', 0) or 0)
            industry = str(row.get('æ‰€å±è¡Œä¸š', 'æœªçŸ¥') or 'æœªçŸ¥')
            volume_ratio = float(row.get('é‡æ¯”', 1.0) or 1.0)
            
            # è¿‡æ»¤å¼±åŠ¿è‚¡
            if burst_count > 3:
                continue
            if turnover_rate < 5:
                continue
            if amount < 100000000:  # æˆäº¤é¢ < 1äº¿
                continue
            
            # ä½¿ç”¨æ˜æ—¥æ½œåŠ›é€‚é…å™¨è¿›è¡Œè¯„ä¼° (Ambushç­–ç•¥)
            try:
                # å»¶è¿Ÿå¯¼å…¥ä»¥é¿å…å¾ªç¯ä¾èµ–
                from ..core.quant.adapters import TomorrowCandidateAdapter
                
                adapter = TomorrowCandidateAdapter()
                
                # æ„é€ é€‚é…å™¨éœ€è¦çš„è¾“å…¥æ•°æ®
                candidate_data = {
                    'code': code,
                    'name': name,
                    'current_price': current_price,
                    'change_percent': change_percent,
                    'turnover_rate': turnover_rate,
                    'amount': amount,
                    'volume_ratio': volume_ratio,
                    'industry': industry,
                    'limit_up_time': seal_time,
                    'burst_count': burst_count
                }
                
                # è°ƒç”¨é€‚é…å™¨ (å†…éƒ¨ä¼šæ‰§è¡Œ: 5ç»´è¯„åˆ† -> å†å²æ•°æ®è·å– -> Ambushç­–ç•¥è¯„ä¼°)
                # æ³¨æ„: å¦‚æœå†å²æ•°æ®ä¸è¶³ï¼Œè¿™é‡Œä¼šè¿”å› None (å¼ºåˆ¶è¦æ±‚çœŸå®æ•°æ®)
                result = await adapter.adapt_tomorrow_candidate(candidate_data)
                
                if result is None:
                    logger.debug(f"Ambushè·³è¿‡ {code}: æ•°æ®ä¸è¶³æˆ–ä¸ç¬¦åˆæ¡ä»¶")
                    continue
                
                # è§£åŒ…ç»“æœ
                (
                    probability,
                    unified_score,
                    strength_level,
                    risk_level,
                    reasons,
                    risks,
                    ambush_score,
                    ambush_factors
                ) = (
                    result['probability'],
                    result['unifiedScore'],
                    result['strengthLevel'],
                    result['riskLevel'],
                    result['reasons'],
                    result['risks'],
                    result.get('ambushScore', 0),
                    result.get('ambushFactors', {})
                )
                
                # æ„é€ è¿”å›å¯¹è±¡
                candidates.append({
                    'code': code,
                    'name': name,
                    'firstBoardTime': seal_time,
                    'sealAmount': round(amount / 1e8, 2),
                    'probability': probability,
                    'unifiedScore': unified_score,
                    'strengthLevel': strength_level,
                    'riskLevel': risk_level,
                    'ambushScore': ambush_score,      # æ–°å¢: æ½œä¼è¯„åˆ†
                    'ambushFactors': ambush_factors,  # æ–°å¢: æ½œä¼å› å­
                    'scoreBreakdown': result.get('scoreBreakdown', {}),
                    'reason': f'é¦–æ¿æ½œä¼ï¼›Ambushè¯„åˆ†{ambush_score:.0f}ï¼›{ambush_factors.get("trend_intensity", "è¯„çº§")}',
                    'reasons': reasons,
                    'risks': risks,
                    'theme': industry,
                    'technicalScore': int(ambush_factors.get('score_vol', 60)),
                    'marketScore': int(ambush_factors.get('score_trend', 60)),
                    'fundScore': int(ambush_factors.get('score_basic', 60)),
                    'currentPrice': current_price,
                    'changePercent': change_percent,
                    'turnoverRate': turnover_rate,
                    'burstCount': burst_count
                })
                
            except Exception as e:
                logger.error(f"Ambushè¯„ä¼°å¤±è´¥ {code}: {e}")
                continue
            
            if len(candidates) >= limit:
                break
        
        # æŒ‰Ambushåˆ†æ•°å’Œæ¦‚ç‡æ’åº
        candidates.sort(key=lambda x: (x.get('ambushScore', 0), x['probability']), reverse=True)
        
        logger.info(f"âœ… è¿”å› {len(candidates)} åªAmbushä¼˜é€‰è‚¡")
        
        return {
            "code": 200,
            "message": "success",
            "data": {
                "candidates": candidates,
                "total_count": len(candidates),
                "update_time": datetime.now().isoformat(),
                "date": data_date
            }
        }
        
    except ImportError:
        logger.error("akshare æœªå®‰è£…")
        return {"code": 500, "message": "akshareæœªå®‰è£…", "data": {"candidates": []}}
    except Exception as e:
        logger.error(f"è·å–äºŒæ¿å€™é€‰å¤±è´¥: {e}")
        return {"code": 500, "message": str(e), "data": {"candidates": []}}


# =============================================================================
# å®æ—¶é¢„æµ‹æ¥å£ï¼ˆç›¯ç›˜é›·è¾¾ç”¨ï¼‰
# =============================================================================
@router.get("/realtime-predictions")
async def get_realtime_predictions(limit: int = 50):
    """
    å®æ—¶æ¶¨åœé¢„æµ‹ï¼ˆç›¯ç›˜é›·è¾¾ï¼‰
    
    è¿”å›åˆ†æ—¶æ®µçš„æ¶¨åœé¢„æµ‹æ•°æ®ï¼Œç”¨äºç›¯ç›˜é›·è¾¾ç»„ä»¶
    """
    try:
        df, data_date = await _get_zt_pool_df()
        
        if df is None or df.empty:
            return {
                "code": 200,
                "message": "æš‚æ— æ¶¨åœæ•°æ®",
                "data": {
                    "segments": [],
                    "statistics": {"total_stocks": 0},
                    "update_time": datetime.now().isoformat()
                }
            }
        
        # æ—¶é—´æ®µå®šä¹‰ - IDä¸å‰ç«¯activeTabåŒ¹é…
        time_segments = [
            {"id": "auction", "name": "ğŸš€ å¼€ç›˜å†²åˆº", "period": "09:30-10:00", "description": "å¼€ç›˜30åˆ†é’Ÿå†…æ¶¨åœ"},
            {"id": "anomaly", "name": "ğŸ“ˆ æ—©ç›˜ä¸»å‡", "period": "10:00-11:00", "description": "æ—©ç›˜ä¸»å‡é˜¶æ®µ"},
            {"id": "breakthrough", "name": "ğŸ”„ åˆç›˜å‘åŠ›", "period": "11:00-13:30", "description": "åˆç›˜å‰å"},
            {"id": "late", "name": "âš¡ å°¾ç›˜çªè¢­", "period": "13:30-15:00", "description": "å°¾ç›˜æ‹‰å‡"}
        ]

        
        # æŒ‰å°æ¿æ—¶é—´åˆ†ç±»
        segmented_stocks = {i: [] for i in range(len(time_segments))}
        
        for _, row in df.head(100).iterrows():
            code = str(row.get('ä»£ç ', ''))
            name = str(row.get('åç§°', ''))
            change_percent = float(row.get('æ¶¨è·Œå¹…', 0) or 0)
            price = float(row.get('æœ€æ–°ä»·', 0) or 0)
            turnover_rate = float(row.get('æ¢æ‰‹ç‡', 0) or 0)
            amount = float(row.get('æˆäº¤é¢', 0) or 0)
            seal_time = str(row.get('é¦–æ¬¡å°æ¿æ—¶é—´', '') or '')
            consecutive_days = int(row.get('è¿æ¿æ•°', 1) or 1)
            volume_ratio = float(row.get('é‡æ¯”', 1.0) or 1.0)
            
            # ä½¿ç”¨ç»Ÿä¸€5ç»´è¯„åˆ†ç³»ç»Ÿ
            try:
                scorer = get_scorer()
                metrics = StockMetrics(
                    code=code,
                    name=name,
                    price=price,
                    change_pct=change_percent,
                    turnover_rate=turnover_rate,
                    amount=amount,
                    volume_ratio=volume_ratio,
                )
                result = scorer.score(metrics)
                score = result.total_score
                level = result.strength_level.value
                risk = result.risk_level.value
                reasons = result.reasons
            except Exception as e:
                logger.warning(f"è¯„åˆ†å¤±è´¥ {code}: {e}")
                # å›é€€åˆ°ç®€åŒ–è¯„åˆ†
                score = min(100, change_percent * 8 + turnover_rate * 2 + min(amount / 1e7, 10) * 5)
                level = "æé«˜" if score >= 85 else "é«˜" if score >= 75 else "ä¸­é«˜" if score >= 65 else "ä¸­"
                risk = "é«˜é£é™©" if change_percent >= 7 else "ä¸­ç­‰"
                reasons = [f"æ¶¨å¹…{change_percent:.2f}%"]
            
            stock_data = {
                "code": code,
                "name": name,
                "price": price,
                "changePercent": change_percent,
                "turnoverRate": turnover_rate,
                "amount": amount,
                "volumeRatio": volume_ratio,
                "predictionScore": round(score, 1),
                "predictionLevel": level,
                "riskLevel": risk,
                # æ–°å¢: 5ç»´è¯„åˆ†è¯¦æƒ…
                "scoreBreakdown": {
                    "changeScore": result.change_score if 'result' in locals() else 0,
                    "turnoverScore": result.turnover_score if 'result' in locals() else 0,
                    "volumeScore": result.volume_score if 'result' in locals() else 0,
                    "shapeScore": result.shape_score if 'result' in locals() else 0,
                    "comboScore": result.combo_score if 'result' in locals() else 0,
                },
                "sealTime": seal_time,
                "consecutive_days": consecutive_days,
                "predictionReasons": reasons + ([f"{consecutive_days}è¿æ¿"] if consecutive_days > 1 else ["é¦–æ¿"])
            }
            
            # æ ¹æ®å°æ¿æ—¶é—´åˆ†ç±»
            segment_id = 0
            if seal_time and len(seal_time) >= 4:
                hhmm = seal_time[:4].replace(':', '')
                if hhmm <= '1000':
                    segment_id = 0
                elif hhmm <= '1100':
                    segment_id = 1
                elif hhmm <= '1330':
                    segment_id = 2
                else:
                    segment_id = 3
            
            segmented_stocks[segment_id].append(stock_data)
        
        # æ„å»ºè¿”å›æ•°æ®
        result_segments = []
        total_stocks = 0
        
        for i, segment_info in enumerate(time_segments):
            stocks = segmented_stocks[i][:limit]
            stocks.sort(key=lambda x: x['predictionScore'], reverse=True)
            total_stocks += len(stocks)
            
            # å‰ç«¯æœŸæœ›çš„æ ¼å¼: {id, name, description, stocks, count}
            result_segments.append({
                "id": str(segment_info["id"]),  # å‰ç«¯ç”¨å­—ç¬¦ä¸²IDåŒ¹é…tab
                "name": segment_info["name"],
                "description": segment_info["description"],
                "stocks": stocks,
                "count": len(stocks)
            })

        
        return {
            "code": 200,
            "message": "success",
            "data": {
                "segments": result_segments,
                "statistics": {
                    "total_stocks": total_stocks,
                    "segments_count": len(time_segments)
                },
                "update_time": datetime.now().isoformat(),
                "date": data_date
            }
        }
        
    except ImportError:
        logger.error("akshare æœªå®‰è£…")
        return {"code": 500, "message": "akshareæœªå®‰è£…", "data": {"segments": []}}
    except Exception as e:
        logger.error(f"è·å–å®æ—¶é¢„æµ‹å¤±è´¥: {e}")
        return {"code": 500, "message": str(e), "data": {"segments": []}}


@router.get("/anomaly-radar")
async def get_anomaly_radar(limit: int = 50):
    """
    ç›˜ä¸­å¼‚åŠ¨é›·è¾¾ - å…¨å¸‚åœºæ‰«æ
    
    æ‰«æå…¨å¸‚åœºè‚¡ç¥¨ï¼Œæ£€æµ‹ä»·æ ¼/é‡æ¯”/æ¢æ‰‹å¼‚åŠ¨ï¼Œ
    è¿”å›æ¶¨åœå‰çš„æ½œåŠ›è‚¡ç¥¨ï¼ˆè€Œéå·²æ¶¨åœè‚¡ç¥¨ï¼‰
    
    å¼‚åŠ¨æ¡ä»¶:
    - æ¶¨å¹… >= 5% (æ¥è¿‘æ¶¨åœ)
    - é‡æ¯” >= 3 (æˆäº¤æ”¾å¤§)
    - æ¢æ‰‹ç‡ >= 3% (æ´»è·ƒäº¤æ˜“)
    """
    try:
        from ..core.quant.anomaly_scanner import get_scanner
        
        logger.info("ğŸ” æ‰§è¡Œå…¨å¸‚åœºå¼‚åŠ¨æ‰«æ...")
        
        scanner = get_scanner()
        
        # æ£€æŸ¥æ˜¯å¦äº¤æ˜“æ—¶é—´
        if not scanner.is_trading_time():
            return {
                "code": 200,
                "message": "éäº¤æ˜“æ—¶é—´",
                "data": {
                    "candidates": [],
                    "is_trading_time": False,
                    "update_time": datetime.now().isoformat()
                }
            }
        
        # æ‰§è¡Œæ‰«æ
        candidates = await scanner.scan()
        
        # è½¬æ¢ä¸ºå“åº”æ ¼å¼
        result_candidates = []
        for candidate in candidates[:limit]:
            result_candidates.append({
                "code": candidate.code,
                "name": candidate.name,
                "price": candidate.price,
                "changePct": candidate.change_pct,
                "volumeRatio": candidate.volume_ratio,
                "turnoverRate": candidate.turnover_rate,
                "amount": candidate.amount,
                "speed1m": candidate.speed_1m,
                "speed3m": candidate.speed_3m,
                "anomalyScore": candidate.anomaly_score,
                "anomalyTypes": [t.value for t in candidate.anomaly_types],
                "detectedAt": candidate.detected_at.isoformat(),
            })
        
        logger.info(f"âœ… å¼‚åŠ¨æ‰«æå®Œæˆ: {len(result_candidates)} åªå€™é€‰")
        
        return {
            "code": 200,
            "message": "success",
            "data": {
                "candidates": result_candidates,
                "is_trading_time": True,
                "total_scanned": len(candidates),
                "update_time": datetime.now().isoformat()
            }
        }
        
    except Exception as e:
        logger.error(f"å¼‚åŠ¨æ‰«æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return {"code": 500, "message": str(e), "data": {"candidates": []}}


@router.get("/engine-status")
async def get_engine_status():
    """
    è·å–å®æ—¶å¼•æ“çŠ¶æ€
    """
    try:
        from ..core.quant.realtime_engine import get_engine
        
        engine = get_engine()
        return {
            "code": 200,
            "message": "success",
            "data": engine.get_stats()
        }
    except Exception as e:
        return {"code": 500, "message": str(e), "data": {}}


@router.post("/start-radar")
async def start_radar_engine():
    """
    å¯åŠ¨å¼‚åŠ¨é›·è¾¾å®æ—¶å¼•æ“
    
    å¯åŠ¨åæ¯3ç§’è‡ªåŠ¨æ‰«æä¸€æ¬¡å…¨å¸‚åœºï¼Œå‘ç°å¼‚åŠ¨è‚¡ç¥¨åæ¨é€
    """
    try:
        from ..core.quant.realtime_engine import get_engine
        from .quant import get_engine_state, broadcast_signal
        
        engine = get_engine(broadcast_callback=broadcast_signal)
        await engine.start()
        
        return {
            "code": 200,
            "message": "å®æ—¶é›·è¾¾å·²å¯åŠ¨",
            "data": engine.get_stats()
        }
    except Exception as e:
        logger.error(f"å¯åŠ¨å®æ—¶é›·è¾¾å¤±è´¥: {e}")
        return {"code": 500, "message": str(e), "data": {}}


@router.post("/stop-radar")
async def stop_radar_engine():
    """
    åœæ­¢å¼‚åŠ¨é›·è¾¾å®æ—¶å¼•æ“
    """
    try:
        from ..core.quant.realtime_engine import stop_engine
        
        await stop_engine()
        
        return {
            "code": 200,
            "message": "å®æ—¶é›·è¾¾å·²åœæ­¢",
            "data": {}
        }
    except Exception as e:
        logger.error(f"åœæ­¢å®æ—¶é›·è¾¾å¤±è´¥: {e}")
        return {"code": 500, "message": str(e), "data": {}}

